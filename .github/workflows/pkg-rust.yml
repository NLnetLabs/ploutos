# GitHub Actions workflow for building and testing O/S packages.
#
# Workflow speed:
# ===============
# This workflow uses GitHub Actions caching to avoid rebuilding Rust cargo-deb, cargo generate-rpm and our compiled
# dependencies on every run. At the time of writing the GH cache contents expire after a week if not used so the next
# build may be much slower as it will have to re-download/build/install lots of Rust crates.
#
# This workflow does NOT use the lewagon/wait-on-check-action GitHub Action to enable individual sub-jobs of a matrix
# job to wait only for their corresponding "upstream" matrix sub-job (e.g. DEB packaging for x86-64 doesn't need to
# wait on cross-compilation while DEB packaging for ARMv7 does need to wait but only for the ARMv7 cross-compile but
# not for the AARCH64 cross-compile). It was tried, it was great, it speeds up the workflow, but it was unreliable.
# There are known issues with the GitHub Action and having a fragile workflow fail sporadically because the wait
# wrongly proceeds to the next step before the dependent step completed successfully is not acceptable. Perhaps this
# will be better later, or an alternative approach exists that has not yet been found.
#
# DEB/RPM packaging:
# ==================
# DEB and RPM packages are built inside Docker containers as GH Runners have extra libraries and packages installed
# which can cause package building to succeed but package installation on a real target O/S to fail, due to being built
# against too recent version of a package such as libssl or glibc.
#
# Packages are built using the cargo deb and cargo generate-rpm projects, not using official Debian and RedHat tools.
# This allows us to keep the configuration in `Cargo.toml` but can mean that we sometimes hit limitations of those
# tools (e.g. we contributed systemd unit activation support to cargo deb to overcome that lacking capability).
#
# DEB/RPM testing:
# ================
# DEB and RPM packages are tested inside LXC/LXD (now Incus) containers because Docker containers don't by default
# support init managers such as systemd but we want to test systemd service unit installation and activation.
#
# RHEL 8/CentOS 8 support:
# ========================
# We were building with the now discontinued CentOS 8. We continue to build them in a CentOS 8 Docker image but install
# packages from the CentOS 8 vault to work around the forced breakage introduced by RedHat. For testing we were forced
# to switch to using a Rocky Linux (CentOS 8 compatible) LXC/LXD image because the CentOS 8 LXC/LXD image was pulled
# from the LXC/LXD image repositories. In future we may want to explicitly build for Rocky Linux instead or as well as
# CentOS 8.
#
# Docker packaging:
# =================
# Docker packaging was originally done using Docker Hub but long delays and repeated spurious failures caused us to
# migrate Docker packaging to GitHub Actions and which is now part of this workflow.
#
# Images use an Alpine base image for reduced image size and thus download time, and also for faster and simpler
# installation of dependencies (apk add is way faster and simpler than apt-get install for example). However Alpine is
# MUSL based rather than GLIBC based, so cross-compiled binaries (see below) must target MUSL when intending to be
# used within a Docker container.
#
# Images are built using Docker Buildkit (officially supported by Docker and used by default by the Docker Build Push
# GitHub Action) which speeds up especially the non-x86-64 architecture case.
#
# Per architecture images are built and pushed to Docker Hub with xxx-<arch> tags, and then a Docker Manifest is
# created which groups these images into a single multi-arch image without the -<arch> extension on the tag. The
# manifest is then also pushed to Docker Hub. In the case of a release tag (a "v*" Git tag that does not contain a
# dash "-" character, i.e. is not a release candidate e.g. v0.1.2-rc3) two manifests are pushed: one for the release
# tag, e.g. nlnetlabs/<app>:v0.1.2; and one for the "latest" tag, e.g. "nlnetlabs/<app>:latest" (to enable Docker users
# to just run `docker run nlnetlabs/<app>` and get the latest stable release without having to know/specify the actual
# version).
#
# Building of both x86-64 and non-x86-64 architecture images are handled by a single Dockerfile which supports two
# modes of operation. In the default 'build' mode our app is compiled within the Docker container and only the final
# artifacts are kept in the final Docker image. In the alternate 'copy' mode our binaries are copied into the
# build container and compilation within the container is skipped.
#
# Multi-arch image creation is NOT done using Docker Buildkit multi-arch support because (a) that does not support
# configuring the different invocations of the Dockerfile differently (e.g. with MODE=copy for the non-x86-64 cases
# and providing different the binaries to copy in to the image in each case) and (b) because it compiles our app in
# parallel for each architecture at once on a single GitHub Actions runner host which is VERY SLOW [1] even for just a
# couple of architectures. Instead we leverage the GitHub Actions matrix building support to build each image in
# parallel. This means however that we have to manually invoke the `docker manifest` command as it is not handled
# automagically for us.
#
# [1]: https://github.com/moby/buildkit/blob/master/docs/multi-platform.md#builds-are-very-slow-through-emulation
#
# Docker authentication:
# ======================
# Publication to Docker Hub depends on a Docker Hub username and access token being available in the GitHub secrets
# available to this workflow.
#
# Package publication:
# ====================
# Docker packages are published immediately to Docker Hub. DEB and RPM packages are only available to NLnet Labs team
# members with access to the workflow artifacts. Publication of DEB and RPM packages to packages.nlnetlabs.nl requires
# that the separate packaging process outside of GitHub be invoked manually.
#
# Non-x86-64 packaging:
# ====================
# This workflow uses the Rust Tools team Cargo Cross project to cross-compile for architectures other than x86 64, e.g.
# ARMv7/armhf and ARM64/aarch64.
#
# Note: Different tools (rustc, QEmu, Docker, etc) use slightly different names for these targets which can be
# confusing.
#
# Cross-compilation is NOT done using the support built-in to Cargo because this requires for each target architecture
# that you manually install the appropriate toolchain, set the appropriate environment variables, install the
# appropriate strip tool, and store with the source code a .cargo/config.toml file telling Cargo which tool paths to
# use for which architecture. However this comes with a couple of limitations: (a) Cargo Cross itself uses Docker and
# has known issues running Docker-in-Docker from within a Docker container (which is how what was the main job of this
# workflow runs), (b) we are "limited" to base images/architectures supported by Cargo Cross (but there are quite
# a few of these) and (c) if the base Cargo Cross image doesn't include packages or tooling needed by `cargo build`
# then building will fail. For these reasons cross compilation is done as a pre-job in this workflow (so that it can
# run on the GitHub runner Host rather than inside a Docker container).
#
# Non-x86-64 testing:
# ===================
# Only x86-64 architecture packages are sanity checked. Non-x86-64 architecture packages are built but not tested as
# the binaries won't run on the x86-64 GitHub runner host, Docker or LXC/LXD containers. It might be possible to use
# QEmu for this but that is not done at this time.
#
# Artifacts:
# ==========
# The output of this workflow is two-fold:
#   - Images pushed directly to Docker Hub.
#   - Artifacts are uploaded to GitHub on workflow completion and appear as-if attached to the workflow run.
# The latter are consumed by the separate manual external process for publishing to packages.nlnetlabs.nl.
#
# This workflow also uses artifacts internally to pass cross-compiled binares from one workflow job to another.
#   - Cross-compiled binary artifacts are uploaded to GitHub by the 'cross' job.
#   - Both the 'pkg' and 'docker' jobs download these cross-compiled binary artifacts for inclusion in the
#     packages they create.
# Such 'internal' artifacts are named with a 'tmp-' prefix and are ignored by the separate manual external process
# for publishing to packages.nlnetlabs.nl.

name: Packaging

# Designate this workflow as a GitHub Actions "reusable" workflow.
# See: https://docs.github.com/en/actions/using-workflows/reusing-workflows
on:
  workflow_call:
    inputs:
      runs_on:
        description: "An optional runner label to direct GitHub Actions to your desired (e.g. self-hosted) runner. Defaults to ubuntu-22.04."
        required: false
        type: string
        # Don't use 'ubuntu-latest' as that could causes unexpected changes to occur when it is repointed at a newer
        # O/S release.
        default: 'ubuntu-22.04'
      cross_runs_on:
        description: "An optional runner label to direct GitHub Actions to your desired (e.g. self-hosted) runner from cross-compilation jobs. Defaults to the value of runs_on."
        required: false
        type: string
        default: ''

      artifact_prefix:
        description: "An optional prefix to apply to generated artifact names. Intended for internal testing."
        required: false
        type: string
        default: ''
      cross_build_rules:
        description: "This input is deprecated. Cross build targets will be determined automatically."
        required: false
        type: string
        default: ''
      cross_max_wait_mins:
        description: "The maximum number of minutes the pkg and/or docker builds will wait for the cross-compiled artifact to become available. Defaults to 10 minutes."
        required: false
        type: string
        default: '10'
      strict_mode:
        description: "If true, certain types of potential spurious warning or error that are usually ignored will instead be considered fatal. Defaults to false."
        required: false
        type: boolean
        default: false
      manifest_dir:
        description: "The path to a directory containing the Cargo.toml file to use instead of the Cargo.toml in the root directory of the Git clone."
        required: false
        type: string
        default: ''
      workspace_package:
        description: "If provided, take [package] settings from the Cargo.toml of this member of the workspace (rooted at manifest_dir, if specified)."
        required: false
        type: string
        default: ''

      package_build_rules:
        description: "A relative path to a YAML file, or a YAML string, containing a GitHub Actions matrix with 'pkg' (your app name), Docker 'image' (image <os>:<rel>), 'target' (x86_64, or a Rust target triple), 'extra_build_args' (optional), 'os' (optional) fields. See also: https://doc.rust-lang.org/nightly/rustc/platform-support.html"
        required: false
        type: string
        default: '{}'
      package_test_rules:
          description: "'use_package_build_rules' (default), 'none', or a relative path to a YAML file, or a YAML string, containing a GitHub Actions matrix with 'pkg' (from package_build_rules), LXC 'image' (<dist>:<rel>), 'target' (from package_build_rules) and 'mode' (fresh-install or upgrade-from-published). See also: https://uk.lxd.images.canonical.com/"
          required: false
          type: string
          default: 'use_package_build_rules'

      # Using Docker Hub terminology, for a Docker image named nlnetlabs/krill:v0.1.2-arm64:
      #   - The Organization would be 'nlnetlabs'.
      #   - The Repository would be 'krill'.
      #   - The Tag would be v0.1.2-arm64
      # Collectively I refer to the combination of <org>/<repo>:<tag> as the 'image' name,
      docker_org:
        required: false
        type: string
        default: ''
      docker_repo:
        required: false
        type: string
        default: ''
      docker_context_path:
        description: "Relative path to use as the Docker build context. Defaults to the root of the git clone, i.e. '.'."
        required: false
        type: string
        default: '.'
      docker_file_path:
        description: "Relative path to the Dockerfile to build. Defaults to the Dockerfile in the root of the git clone, i.e. './Dockerfile'."
        required: false
        type: string
        default: './Dockerfile'
      docker_build_rules:
        description: "A relative path to a YAML file, or a YAML string, containing a GitHub Actions matrix with platform, shortname, target (required if mode is copy), mode (optional: build (default) or copy) and cargo_args (optional) fields."
        required: false
        type: string
        default: '{}'
      docker_sanity_check_command:
        description: "A command to run inside the Docker container to sanity check that it is working as expected."
        required: false
        type: string
        default: ''

      deb_extra_build_packages:
        description: "A space separated set of additional Debian packages to install when (not cross) compiling."
        required: false
        type: string
        default: ''
      deb_apt_key_url:
        description: "When upgrading from a previously published package, this is the URL to the published repository key. Defaults to the NLnet Labs repository key.. Can also be specified per test case."
        required: false
        type: string
        default: 'https://packages.nlnetlabs.nl/aptkey.asc'
      deb_apt_source:
        description: "When upgrading from a previously published package, this is either lines of text to write to an APT sources file, or the relative path to an APT sources file to install. Defaults to the NLnet Labs repository. Can use ${OS_NAME} and ${OS_REL} placeholders.. Can also be specified per test case."
        required: false
        type: string
        default: 'deb [arch=amd64] https://packages.nlnetlabs.nl/linux/${OS_NAME}/ ${OS_REL} main'

      cross_build_args:
        description: "Extra arguments to cargo build when cross-compiling, e.g. `--features static-openssl`."
        required: false
        type: string
        default: ''

      next_ver_label:
        description: "A tag suffix that denotes an in-development rather than release version, e.g. `dev``."
        required: false
        type: string
        default: dev

      rpm_extra_build_packages:
        description: "A space separated set of additional RPM packages to install when (not cross) compiling."
        required: false
        type: string
        default: ''
      rpm_scriptlets_path:
        description: "The path to a TOML file defining one or more of pre_install_script, post_install_script and/or post_uninstall_script."
        required: false
        type: string
        default: ''
      rpm_yum_key_url:
        description: "When upgrading from a previously published package, this is the URL to the published repository key. Defaults to the NLnet Labs repository key. Can also be specified per test case."
        required: false
        type: string
        default: 'https://packages.nlnetlabs.nl/aptkey.asc'
      rpm_yum_repo:
        description: "When upgrading from a previously published package, this is either lines of text to write to an RPM repo file, or the relative path to an RPM repo file to install. Defaults to the NLnet Labs repository. Can use ${OS_NAME} and ${OS_REL} placeholders. Can also be specified per test case."
        required: false
        type: string
        default: |
          [nlnetlabs]
          name=NLnet Labs
          baseurl=https://packages.nlnetlabs.nl/linux/centos/$releasever/main/$basearch
          enabled=1
      rpm_yum_extra_args:
        description: "When upgrading from a previously published package, pass these additional arguments to yum install. Can also be specified per test case."
        required: false
        type: string
        default: ''

      package_test_always_add_repo:
          description: "When testing a package, always add deb_apt_source and/or rpm_yum_repo, not only during package upgrade testing."
          required: false
          type: boolean
          default: false
      package_test_scripts_path:
        description: "The path to find scripts for running tests. Invoked scripts take a single argument: post-install or post-upgrade."
        required: false
        type: string
        default: ''

    secrets:
      DOCKER_HUB_ID:
        required: false
      DOCKER_HUB_TOKEN:
        required: false

    outputs:
      docker_images_published:
        description: "Whether publishing of Docker images was done or not."
        value: ${{ jobs.docker.outputs.published }}
      docker_manifest_published:
        description: "Whether publishing of the Docker manifest was done or not."
        value: ${{ jobs.docker-manifest.outputs.published }}

defaults:
  run:
    # see: https://docs.github.com/en/actions/reference/workflow-syntax-for-github-actions#using-a-specific-shell
    shell: bash --noprofile --norc -eo pipefail -x {0}

env:
  DEBIAN_FRONTEND: noninteractive
  # See: https://github.com/actions/checkout/issues/1809
  ACTIONS_ALLOW_USE_UNSECURE_NODE_VERSION: true

jobs:
  # -------------------------------------------------------------------------------------------------------------------
  # Job: 'prepare'
  # -------------------------------------------------------------------------------------------------------------------
  # Validate and pre-process inputs.
  prepare:
    runs-on: ${{ inputs.runs_on }}
    outputs:
      cargo_name: ${{ steps.verify_inputs.outputs.cargo_name }}
      cargo_package_toml_path: ${{ steps.verify_inputs.outputs.cargo_package_toml_path }}
      cargo_manifest_path_arg: ${{ steps.verify_inputs.outputs.cargo_manifest_path_arg }}
      cargo_read_manifest_path_arg: ${{ steps.verify_inputs.outputs.cargo_read_manifest_path_arg }}
      cargo_workspace_package_arg: ${{ steps.verify_inputs.outputs.cargo_workspace_package_arg }}
      has_docker_secrets: ${{ steps.verify_inputs.outputs.has_docker_secrets }}
      all_repo_and_tag_pairs: ${{ steps.encode.outputs.all_repo_and_tag_pairs }}
      first_repo_and_tag_pair: ${{ steps.encode.outputs.first_repo_and_tag_pair }}
      lower_docker_org: ${{ steps.encode.outputs.lower_docker_org }}
      runs_on: ${{ steps.determine_cross_build_rules.outputs.runs_on }}
      cross_build_rules: ${{ steps.determine_cross_build_rules.outputs.matrix }}
      cross_max_tries: ${{ steps.determine_cross_build_rules.outputs.max_tries }}
      cross_retry_delay_ms: ${{ steps.determine_cross_build_rules.outputs.retry_delay_ms }}
      cross_runs_on: ${{ steps.determine_cross_build_rules.outputs.cross_runs_on }}
      docker_build_rules: ${{ steps.pre_process_rules.outputs.docker_build_rules }}
      package_build_rules: ${{ steps.pre_process_rules.outputs.package_build_rules }}
      package_test_rules: ${{ steps.pre_process_rules.outputs.package_test_rules }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # TODO: extract common code into helper functions
      - name: Pre-process rules
        id: pre_process_rules
        run: |
          if [[ '${{ inputs.cross_build_rules }}' != '' ]]; then
            echo "::warning::The 'cross_build_rules' input is deprecated. Cross build targets will be determined automatically."
          fi

          DOCKER_BUILD_RULES=$(cat <<'EOF'
          ${{ inputs.docker_build_rules }}
          EOF
          )
          if [[ -f "${DOCKER_BUILD_RULES}" ]]; then
            DOCKER_BUILD_RULES_RAW_JSON=$(yq "${DOCKER_BUILD_RULES}" -I=0 -p=yaml -o=json)
          else
            DOCKER_BUILD_RULES_RAW_JSON=$(echo "${DOCKER_BUILD_RULES}" | yq -I=0 -p=yaml -o=json)
          fi

          # Convert string values to array of single string values (as GitHub matrix values must be arrays).
          DOCKER_BUILD_RULES_PROCESSED_JSON=$(echo ${DOCKER_BUILD_RULES_RAW_JSON} | jq 'with_entries(if .value | type == "string" then .value |= [.] elif .value | type != "array" then error("rule values must be strings or arrays") else . end)')

          # Rename "crosstarget" keys to "target" (we support "crosstarget" for backward compatibility).
          DOCKER_BUILD_RULES_PROCESSED_JSON=$(echo ${DOCKER_BUILD_RULES_PROCESSED_JSON} | jq '(.. | select(has("crosstarget")?)) |= with_entries(if .key == "crosstarget" then .key = "target" else . end)')

          echo "docker_build_rules<<END_OF_DOCKER_BUILD_RULES" >> $GITHUB_OUTPUT
          echo ${DOCKER_BUILD_RULES_PROCESSED_JSON} | jq >> $GITHUB_OUTPUT
          echo 'END_OF_DOCKER_BUILD_RULES' >> $GITHUB_OUTPUT

          PACKAGE_BUILD_RULES=$(cat <<'EOF'
          ${{ inputs.package_build_rules }}
          EOF
          )
          if [[ -f "${PACKAGE_BUILD_RULES}" ]]; then
            PACKAGE_BUILD_RULES_RAW_JSON=$(yq "${PACKAGE_BUILD_RULES}" -I=0 -p=yaml -o=json)
          else
            PACKAGE_BUILD_RULES_RAW_JSON=$(echo "${PACKAGE_BUILD_RULES}" | yq -I=0 -p=yaml -o=json)
          fi

          # Convert string values to array of single string values (as GitHub matrix values must be arrays).
          PACKAGE_BUILD_RULES_ARRAYS_JSON=$(echo ${PACKAGE_BUILD_RULES_RAW_JSON} | jq 'with_entries(if .value | type == "string" then .value |= [.] elif .value | type != "array" then error("rule values must be strings or arrays") else . end)')

          # Don't permute the build job over variables intended only for use by the pkg-test job but which were supplied
          # via package_build_rules as a convenience for the user to avoid having to supply package_test_rules which
          # would be mostly identical to package_build_rules. If we don't remove this we end up causing duplicate Build
          # jobs to be spawned for each different test mode (fresh-install vs upgrade-from-published) which for the
          # pkb job are identical and thus pointless waste and just plain confusing.
          PACKAGE_BUILD_RULES_PROCESSED_JSON=$(echo ${PACKAGE_BUILD_RULES_ARRAYS_JSON} | jq -c 'del(."test-mode") | del(.include[]?."test-mode") | del(."test-exclude")')
          PACKAGE_BUILD_RULES_PROCESSED_JSON=$(echo ${PACKAGE_BUILD_RULES_PROCESSED_JSON} | jq -c 'del(."test-image") | del(.include[]?."test-image")')

          # And now also for the older names for backward compatibility.
          PACKAGE_BUILD_RULES_PROCESSED_JSON=$(echo ${PACKAGE_BUILD_RULES_PROCESSED_JSON} | jq -c 'del(.mode) | del(.include[]?.mode)')

          # Exclude centos:7 from building because the CentOS package mirror is no longer available.
          # Specifically:
          #   $ yum update -y
          #   Loaded plugins: fastestmirror, ovl
          #   Determining fastest mirrors
          #   Could not retrieve mirrorlist http://mirrorlist.centos.org/?release=7&arch=x86_64&repo=os&infra=container error was
          #   14: curl#6 - "Could not resolve host: mirrorlist.centos.org; Unknown error"
          if [[ "${PACKAGE_BUILD_RULES_PROCESSED_JSON}" != "{}" ]]; then
            CONTROL_JSON=$(echo ${PACKAGE_BUILD_RULES_PROCESSED_JSON} | jq -c)
            MODIFIED_JSON=$(echo ${PACKAGE_BUILD_RULES_PROCESSED_JSON} | jq -c 'del(.image[]? | select(. == "centos:7")) | del(.include[]? | select(.image == "centos:7"))')
            MODIFIED_JSON=$(echo ${MODIFIED_JSON} | jq -c 'del(.include[]? | select(.os == "debian:centos7"))')
            if [[ "${CONTROL_JSON}" != "${MODIFIED_JSON}" ]]; then
              echo "::warning::Removed centos:7 image from package_build_rules because mirrorlist.centos.org is no longer available"
              PACKAGE_BUILD_RULES_PROCESSED_JSON="${MODIFIED_JSON}"
            fi
          fi

          # Exclude ubuntu:xenial as its GLIBC is too old to support Node 20 now required to use GitHub Actions
          if [[ "${PACKAGE_BUILD_RULES_PROCESSED_JSON}" != "{}" ]]; then
            CONTROL_JSON=$(echo ${PACKAGE_BUILD_RULES_PROCESSED_JSON} | jq -c)
            MODIFIED_JSON=$(echo ${PACKAGE_BUILD_RULES_PROCESSED_JSON} | jq -c 'del(.image[]? | select(. == "ubuntu:xenial")) | del(.include[]? | select(.image == "ubuntu:xenial"))')
            MODIFIED_JSON=$(echo ${MODIFIED_JSON} | jq -c 'del(.include[]? | select(.os == "ubuntu:xenial"))')
            if [[ "${CONTROL_JSON}" != "${MODIFIED_JSON}" ]]; then
              echo "::warning::Removed ubuntu:xenial image from package_build_rules because its GLIBC is too old to support Node 20 required by GitHub Actions"
              PACKAGE_BUILD_RULES_PROCESSED_JSON="${MODIFIED_JSON}"
            fi
          fi

          # Exclude ubuntu:bionic as its GLIBC is too old to support Node 20 now required to use GitHub Actions
          if [[ "${PACKAGE_BUILD_RULES_PROCESSED_JSON}" != "{}" ]]; then
            CONTROL_JSON=$(echo ${PACKAGE_BUILD_RULES_PROCESSED_JSON} | jq -c)
            MODIFIED_JSON=$(echo ${PACKAGE_BUILD_RULES_PROCESSED_JSON} | jq -c 'del(.image[]? | select(. == "ubuntu:bionic")) | del(.include[]? | select(.image == "ubuntu:bionic"))')
            MODIFIED_JSON=$(echo ${MODIFIED_JSON} | jq -c 'del(.include[]? | select(.os == "ubuntu:bionic"))')
            if [[ "${CONTROL_JSON}" != "${MODIFIED_JSON}" ]]; then
              echo "::warning::Removed ubuntu:bionic image from package_build_rules because its GLIBC is too old to support Node 20 required by GitHub Actions"
              PACKAGE_BUILD_RULES_PROCESSED_JSON="${MODIFIED_JSON}"
            fi
          fi

          # Exclude debian:stretch as its GLIBC is too old to support Node 20 now required to use GitHub Actions
          if [[ "${PACKAGE_BUILD_RULES_PROCESSED_JSON}" != "{}" ]]; then
            CONTROL_JSON=$(echo ${PACKAGE_BUILD_RULES_PROCESSED_JSON} | jq -c)
            MODIFIED_JSON=$(echo ${PACKAGE_BUILD_RULES_PROCESSED_JSON} | jq -c 'del(.image[]? | select(. == "debian:stretch")) | del(.include[]? | select(.image == "debian:stretch"))')
            MODIFIED_JSON=$(echo ${MODIFIED_JSON} | jq -c 'del(.include[]? | select(.os == "debian:stretch"))')
            if [[ "${CONTROL_JSON}" != "${MODIFIED_JSON}" ]]; then
              echo "::warning::Removed debian:stretch image from package_build_rules because its GLIBC is too old to support Node 20 required by GitHub Actions"
              PACKAGE_BUILD_RULES_PROCESSED_JSON="${MODIFIED_JSON}"
            fi
          fi

          # Exclude debian:buster because the Debian repository is no longer available.
          # Specifically:
          #   E: The repository 'http://deb.debian.org/debian buster Release' does not have a Release file.
          if [[ "${PACKAGE_BUILD_RULES_PROCESSED_JSON}" != "{}" ]]; then
            CONTROL_JSON=$(echo ${PACKAGE_BUILD_RULES_PROCESSED_JSON} | jq -c)
            MODIFIED_JSON=$(echo ${PACKAGE_BUILD_RULES_PROCESSED_JSON} | jq -c 'del(.image[]? | select(. == "debian:buster")) | del(.include[]? | select(.image == "debian:buster"))')
            MODIFIED_JSON=$(echo ${MODIFIED_JSON} | jq -c 'del(.include[]? | select(.os == "debian:buster"))')
            if [[ "${CONTROL_JSON}" != "${MODIFIED_JSON}" ]]; then
              echo "::warning::Removed debian:buster image from package_build_rules because the http://deb.debian.org/debian buster Release file is no longer available"
              PACKAGE_BUILD_RULES_PROCESSED_JSON="${MODIFIED_JSON}"
            fi
          fi

          echo "package_build_rules<<END_OF_PACKAGE_BUILD_RULES" >> $GITHUB_OUTPUT
          echo ${PACKAGE_BUILD_RULES_PROCESSED_JSON} | jq >> $GITHUB_OUTPUT
          echo 'END_OF_PACKAGE_BUILD_RULES' >> $GITHUB_OUTPUT

          PACKAGE_TEST_RULES=$(cat <<'EOF'
          ${{ inputs.package_test_rules }}
          EOF
          )
          if [[ "${PACKAGE_TEST_RULES}" == 'none' ]]; then
            PACKAGE_TEST_RULES_RAW_JSON='{}'
          elif [[ "${PACKAGE_TEST_RULES}" == 'use_package_build_rules' ]]; then
            PACKAGE_TEST_RULES_RAW_JSON="${PACKAGE_BUILD_RULES_ARRAYS_JSON}"
          elif [[ -f "${PACKAGE_TEST_RULES}" ]]; then
            PACKAGE_TEST_RULES_RAW_JSON=$(yq "${PACKAGE_TEST_RULES}" -I=0 -p=yaml -o=json)
          else
            PACKAGE_TEST_RULES_RAW_JSON=$(echo "${PACKAGE_TEST_RULES}" | yq -I=0 -p=yaml -o=json)
          fi

          # Convert string values to array of single string values (as GitHub matrix values must be arrays).
          PACKAGE_TEST_RULES_PROCESSED_JSON=$(echo ${PACKAGE_TEST_RULES_RAW_JSON} | jq 'with_entries(if .value | type == "string" then .value |= [.] elif .value | type != "array" then error("rule values must be strings or arrays") else . end)')

          # Exclude debian:stretch because the LXC image is no longer available.
          if [[ "${PACKAGE_TEST_RULES_PROCESSED_JSON}" != "{}" ]]; then
            CONTROL_JSON=$(echo ${PACKAGE_TEST_RULES_PROCESSED_JSON} | jq -c)
            MODIFIED_JSON=$(echo ${PACKAGE_TEST_RULES_PROCESSED_JSON} | jq -c 'del(.image[]? | select(. == "debian:stretch")) | del(.include[]? | select(.image == "debian:stretch"))')
            MODIFIED_JSON=$(echo ${MODIFIED_JSON} | jq -c 'del(.include[]? | select(.os == "debian:stretch"))')
            if [[ "${CONTROL_JSON}" != "${MODIFIED_JSON}" ]]; then
              echo "::warning::Removed debian:stretch image from package_test_rules because the LXC/Incus image no longer exists"
              PACKAGE_TEST_RULES_PROCESSED_JSON="${MODIFIED_JSON}"
            fi
          fi

          # Exclude debian:buster because the Debian repository is no longer available.
          # Specifically:
          #   E: The repository 'http://deb.debian.org/debian buster Release' does not have a Release file.
          if [[ "${PACKAGE_TEST_RULES_PROCESSED_JSON}" != "{}" ]]; then
            CONTROL_JSON=$(echo ${PACKAGE_TEST_RULES_PROCESSED_JSON} | jq -c)
            MODIFIED_JSON=$(echo ${PACKAGE_TEST_RULES_PROCESSED_JSON} | jq -c 'del(.image[]? | select(. == "debian:buster")) | del(.include[]? | select(.image == "debian:buster"))')
            MODIFIED_JSON=$(echo ${MODIFIED_JSON} | jq -c 'del(.include[]? | select(.os == "debian:buster"))')
            if [[ "${CONTROL_JSON}" != "${MODIFIED_JSON}" ]]; then
              echo "::warning::Removed debian:buster image from package_test_rules because the http://deb.debian.org/debian buster Release file is no longer available"
              PACKAGE_TEST_RULES_PROCESSED_JSON="${MODIFIED_JSON}"
            fi
          fi

          # Exclude ubuntu:bionic because the LXC image is no longer available.
          if [[ "${PACKAGE_TEST_RULES_PROCESSED_JSON}" != "{}" ]]; then
            CONTROL_JSON=$(echo ${PACKAGE_TEST_RULES_PROCESSED_JSON} | jq -c)
            MODIFIED_JSON=$(echo ${PACKAGE_TEST_RULES_PROCESSED_JSON} | jq -c 'del(.image[]? | select(. == "ubuntu:bionic")) | del(.include[]? | select(.image == "ubuntu:bionic"))')
            MODIFIED_JSON=$(echo ${MODIFIED_JSON} | jq -c 'del(.include[]? | select(.os == "ubuntu:bionic"))')
            if [[ "${CONTROL_JSON}" != "${MODIFIED_JSON}" ]]; then
              echo "::warning::Removed ubuntu:bionic image from package_test_rules because the LXC/Incus image no longer exists"
              PACKAGE_TEST_RULES_PROCESSED_JSON="${MODIFIED_JSON}"
            fi
          fi

          # Exclude centos:7 because we excluded it from building above.
          if [[ "${PACKAGE_TEST_RULES_PROCESSED_JSON}" != "{}" ]]; then
            CONTROL_JSON=$(echo ${PACKAGE_TEST_RULES_PROCESSED_JSON} | jq -c)
            MODIFIED_JSON=$(echo ${PACKAGE_TEST_RULES_PROCESSED_JSON} | jq -c 'del(.image[]? | select(. == "centos:7")) | del(.include[]? | select(.image == "centos:7"))')
            MODIFIED_JSON=$(echo ${MODIFIED_JSON} | jq -c 'del(.include[]? | select(.os == "centos:7"))')
            if [[ "${CONTROL_JSON}" != "${MODIFIED_JSON}" ]]; then
              echo "::warning::Removed centos:7 image from package_test_rules because Ploutos no longer supports building for CentOS 7"
              PACKAGE_TEST_RULES_PROCESSED_JSON="${MODIFIED_JSON}"
            fi
          fi

          # Exclude ubuntu:xenial because the LXC image is no longer available.
          if [[ "${PACKAGE_TEST_RULES_PROCESSED_JSON}" != "{}" ]]; then
            CONTROL_JSON=$(echo ${PACKAGE_TEST_RULES_PROCESSED_JSON} | jq -c)
            MODIFIED_JSON=$(echo ${PACKAGE_TEST_RULES_PROCESSED_JSON} | jq -c 'del(.image[]? | select(. == "ubuntu:xenial")) | del(.include[]? | select(.image == "ubuntu:xenial"))')
            MODIFIED_JSON=$(echo ${MODIFIED_JSON} | jq -c 'del(.include[]? | select(.os == "ubuntu:xenial"))')
            if [[ "${CONTROL_JSON}" != "${MODIFIED_JSON}" ]]; then
              echo "::warning::Removed ubuntu:xenial image from package_test_rules because the LXC/Incus image no longer exists"
              PACKAGE_TEST_RULES_PROCESSED_JSON="${MODIFIED_JSON}"
            fi
          fi

          # Exclude ubuntu:focal because the LXC image is no longer available.
          if [[ "${PACKAGE_TEST_RULES_PROCESSED_JSON}" != "{}" ]]; then
            CONTROL_JSON=$(echo ${PACKAGE_TEST_RULES_PROCESSED_JSON} | jq -c)
            MODIFIED_JSON=$(echo ${PACKAGE_TEST_RULES_PROCESSED_JSON} | jq -c 'del(.image[]? | select(. == "ubuntu:focal")) | del(.include[]? | select(.image == "ubuntu:focal"))')
            MODIFIED_JSON=$(echo ${MODIFIED_JSON} | jq -c 'del(.include[]? | select(.os == "ubuntu:focal"))')
            if [[ "${CONTROL_JSON}" != "${MODIFIED_JSON}" ]]; then
              echo "::warning::Removed ubuntu:focal image from package_test_rules because the LXC/Incus image no longer exists"
              PACKAGE_TEST_RULES_PROCESSED_JSON="${MODIFIED_JSON}"
            fi
          fi

          # Exclude non-x86_64 targets as we only run the tests on x86-64 GitHub runners.
          if [[ "${PACKAGE_TEST_RULES_PROCESSED_JSON}" != "{}" ]]; then
            CONTROL_JSON=$(echo ${PACKAGE_TEST_RULES_PROCESSED_JSON} | jq -c)
            MODIFIED_JSON=$(echo ${PACKAGE_TEST_RULES_PROCESSED_JSON} | jq -c 'del(.target[]? | select(. != "x86_64")) | del(.include[]? | select(.target != "x86_64" and .target != null))')
            if [[ "${CONTROL_JSON}" != "${MODIFIED_JSON}" ]]; then
              echo "::warning::Removed non-x86_64 targets from package_test_rules because testing is only supported for x86_64 targets"
              PACKAGE_TEST_RULES_PROCESSED_JSON="${MODIFIED_JSON}"
            fi
          fi

          # In the test rules, rename "test-mode" key to "mode" and "test-exclude" to "exclude".
          # 'exclude' is used by GitHub Actions itself, while 'mode' has meaning for us. We're renaming them because
          # prefixing them with 'test-' when used in the build rules makes it clearer that they relate to generated
          # default test rules.
          PACKAGE_TEST_RULES_PROCESSED_JSON=$(echo ${PACKAGE_TEST_RULES_PROCESSED_JSON} | jq '(.. | select(has("test-mode")?)) |= with_entries(if .key == "test-mode" then .key = "mode" else . end)')
          PACKAGE_TEST_RULES_PROCESSED_JSON=$(echo ${PACKAGE_TEST_RULES_PROCESSED_JSON} | jq '(.. | select(has("test-exclude")?)) |= with_entries(if .key == "test-exclude" then .key = "exclude" else . end)')

          echo "package_test_rules<<END_OF_PACKAGE_TEST_RULES" >> $GITHUB_OUTPUT
          echo ${PACKAGE_TEST_RULES_PROCESSED_JSON} | jq >> $GITHUB_OUTPUT
          echo 'END_OF_PACKAGE_TEST_RULES' >> $GITHUB_OUTPUT

      - name: Determine cross build rules
        id: determine_cross_build_rules
        run: |
          JSON='${{ steps.pre_process_rules.outputs.docker_build_rules }}'
          DOCKER_TARGETS=$(echo $JSON | jq '.. | .target? | select(. != null)')

          JSON='${{ steps.pre_process_rules.outputs.package_build_rules }}'
          PKG_TARGETS=$(echo $JSON | jq '.. | .target? | select(. != null)')

          # This is a bit ridiculous invoking jq three times... there must be an easier way
          ALL_TARGETS=$(echo ${DOCKER_TARGETS} ${PKG_TARGETS} | jq -s 'flatten | unique | .[] | select(. != "x86_64")' | jq -s)

          RUNS_ON="\"${{ inputs.runs_on }}\""

          if [ "${{ inputs.cross_runs_on }}" == '' ]; then
            CROSS_RUNS_ON="${RUNS_ON}"
          else
            CROSS_RUNS_ON="\"${{ inputs.cross_runs_on }}\""
          fi

          echo "matrix<<END_OF_TARGETS" >> $GITHUB_OUTPUT
          if [ "${ALL_TARGETS}" == '[]' ]; then
            echo '{}' >> $GITHUB_OUTPUT
          else
            echo '{ "target": ' ${ALL_TARGETS} '}' | jq >> $GITHUB_OUTPUT
          fi
          echo "END_OF_TARGETS" >> $GITHUB_OUTPUT
          
          echo "runs_on<<END_OF_RUNS_ON" >> $GITHUB_OUTPUT
          echo '{ "labels": [' ${RUNS_ON} '] }' | jq >> $GITHUB_OUTPUT
          echo "END_OF_RUNS_ON" >> $GITHUB_OUTPUT
    
          echo "cross_runs_on<<END_OF_CROSS_RUNS_ON" >> $GITHUB_OUTPUT
          echo '{ "labels": [' ${CROSS_RUNS_ON} '] }' | jq >> $GITHUB_OUTPUT
          echo "END_OF_CROSS_RUNS_ON" >> $GITHUB_OUTPUT

          # While this delay may seem fairly high, reducing it greatly
          # increases the chances of here or elsewhere in the workflow getting
          # an HTTP 429 Too Many Requests error from the GH API.
          RETRY_DELAY_MS=30000
          MAX_TRIES=$(( ( ${{ inputs.cross_max_wait_mins }} * 60 * 1000 ) / ${RETRY_DELAY_MS} ))
          echo "retry_delay_ms=${RETRY_DELAY_MS}" >> $GITHUB_OUTPUT
          echo "max_tries=${MAX_TRIES}" >> $GITHUB_OUTPUT

      - name: Print rules
        # Disable default use of bash -x for easier to read output in the log
        shell: bash
        run: |
          echo "============================================================================="
          echo "Cross build rules:"
          echo "============================================================================="
          JSON='${{ steps.determine_cross_build_rules.outputs.matrix }}'
          if [[ "${JSON}" != "{}" ]]; then
            echo '${{ steps.determine_cross_build_rules.outputs.matrix }}'
          else
            echo None
          fi

          echo
          echo "============================================================================="
          echo "Docker build rules:"
          echo "============================================================================="
          JSON='${{ steps.pre_process_rules.outputs.docker_build_rules }}'
          if [[ "${JSON}" != "{}" ]]; then
            echo '${{ steps.pre_process_rules.outputs.docker_build_rules }}'
          else
            echo None
          fi

          echo
          echo "============================================================================="
          echo "Package build rules:"
          echo "============================================================================="
          JSON='${{ steps.pre_process_rules.outputs.package_build_rules }}'
          if [[ "${JSON}" != "{}" ]]; then
            echo '${{ steps.pre_process_rules.outputs.package_build_rules }}'
          else
            echo None
          fi

          echo
          echo "============================================================================="
          echo "Packages test rules:"
          echo "============================================================================="
          JSON='${{ steps.pre_process_rules.outputs.package_test_rules }}'
          if [[ "${JSON}" != "{}" ]]; then
            echo '${{ steps.pre_process_rules.outputs.package_test_rules }}'
          else
            echo None
          fi

      - name: Verify inputs
        id: verify_inputs
        run: |
          CARGO_MANIFEST_PATH_ARG=""
          if [[ "${{ inputs.manifest_dir}}" != '' ]]; then
            CARGO_MANIFEST_PATH_ARG="--manifest-path ${{ inputs.manifest_dir }}/Cargo.toml"
          fi
          echo "cargo_manifest_path_arg=${CARGO_MANIFEST_PATH_ARG}" >> $GITHUB_OUTPUT

          CARGO_WORKSPACE_PACKAGE_ARG=""
          if [[ "${{ inputs.workspace_package}}" != '' ]]; then
            CARGO_WORKSPACE_PACKAGE_ARG="--package ${{ inputs.workspace_package }}"
          fi
          echo "cargo_workspace_package_arg=${CARGO_WORKSPACE_PACKAGE_ARG}" >> $GITHUB_OUTPUT

          CARGO_PACKAGE_TOML_PATH=""
          CARGO_READ_MANIFEST_PATH_ARG=""
          if [[ '${{ inputs.manifest_dir }}' != '' ]]; then
            CARGO_PACKAGE_TOML_PATH="${{ inputs.manifest_dir }}/"
          fi
          if [[ '${{ inputs.workspace_package}}' != '' ]]; then
            CARGO_PACKAGE_TOML_PATH="${CARGO_PACKAGE_TOML_PATH}${{ inputs.workspace_package}}/"
          fi
          CARGO_PACKAGE_TOML_PATH="${CARGO_PACKAGE_TOML_PATH}Cargo.toml"

          if [[ "${CARGO_PACKAGE_TOML_PATH}" != "Cargo.toml" ]]; then
            CARGO_READ_MANIFEST_PATH_ARG="--manifest-path ${CARGO_PACKAGE_TOML_PATH}"
          fi

          echo "cargo_package_toml_path=${CARGO_PACKAGE_TOML_PATH}" >> $GITHUB_OUTPUT
          echo "cargo_read_manifest_path_arg=${CARGO_READ_MANIFEST_PATH_ARG}" >> $GITHUB_OUTPUT

          CARGO_NAME=$(cat ${CARGO_PACKAGE_TOML_PATH} | docker run --rm -i sclevine/yj -tj | jq -r .package.name)
          echo "cargo_name=${CARGO_NAME}" >> $GITHUB_OUTPUT

          if [[ '${{ inputs.next_ver_label }}' == '' ]]; then
            echo "::error::Workflow input 'next_ver_label' must be non-empty if set."
            exit 1
          fi

          if [[ '${{ inputs.rpm_scriptlets_path }}' != '' ]]; then
            if [[ ! -f '${{ inputs.rpm_scriptlets_path }}' ]]; then
              echo "::error::Workflow input 'rpm_scriptlets_path' ('${{ inputs.rpm_scriptlets_path }}') must refer to a file in the Git checkout"
              exit 1
            fi
          fi

          if [[ '${{ steps.pre_process_rules.outputs.docker_build_rules }}' != '{}' ]]; then
            if [[ '${{ inputs.docker_org }}' == '' ]]; then
              echo "::error::Workflow input 'docker_org' must be non-empty when 'docker_build_rules' are supplied."
              exit 1
            fi

            if [[ '${{ inputs.docker_repo }}' == '' ]]; then
              echo "::error::Workflow input 'docker_repo' must be non-empty when 'docker_build_rules' are supplied."
              exit 1
            fi
          fi

          if [[ "${{ secrets.DOCKER_HUB_ID }}" != '' || "${{ secrets.DOCKER_HUB_TOKEN }}" != '' ]]; then
            echo "has_docker_secrets=true" >> $GITHUB_OUTPUT
          else
            echo "has_docker_secrets=false" >> $GITHUB_OUTPUT
          fi

      - name: Verify Docker credentials
        if: ${{ steps.pre_process_rules.outputs.docker_build_rules != '{}' && fromJSON(steps.verify_inputs.outputs.has_docker_secrets) == true }}
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_HUB_ID }}
          password: ${{ secrets.DOCKER_HUB_TOKEN }}

      # NOTE: This step does NOT actually tag anything in Docker, either locally or on Docker Hub, it only generates a
      # potential set of string tag values that can be used later in the workflow.
      #
      # Based on the Git ref, e.g. a tag or branch, determine the appropriate tag(s) for the Docker image we will
      # create, e.g. <app>:unstable for a main branch commit, or <app>:v1.2.3 _and_ <app>:latest for a release tag, or
      # <app>:test for anything else. The action also determines a set of potential Docker labels that we might wish to
      # apply to the Docker image, e.g. (these are the actual values the action produced for the v0.10.0 Krill release
      # tag):
      #     org.opencontainers.image.title=krill
      #     org.opencontainers.image.description=RPKI Certificate Authority and Publication Server written in Rust
      #     org.opencontainers.image.url=https://github.com/NLnetLabs/krill
      #     org.opencontainers.image.source=https://github.com/NLnetLabs/krill
      #     org.opencontainers.image.version=v0.10.0
      #     org.opencontainers.image.created=2022-09-05T14:52:15.182Z
      #     org.opencontainers.image.revision=2c00aa05e2299ca8a0994f7d054231e3a5cd8d25
      #     org.opencontainers.image.licenses=MPL-2.0
      #
      # The results of the action are available to subsequent steps via steps.meta.output.tags and
      # steps.meta.output.labels (both line-break separated).
      #
      # The rules defined for the docker/metadata-action below are as follows, assuming:
      #   with:
      #     images: <app>
      # 
      # On push of a Git tag to refs/tags/v1.2.3 the Docker tags will be '<app>:v1.2.3' and '<app>:latest'
      # because of:
      #   type=semver,pattern={{version}},prefix=v
      #   type=raw,value=latest,enable=${{ github.ref != 'refs/heads/main' && !contains(github.ref, '-') }}
      #                                    ^^^^^^^^^^^^^ true, not main       ^^^^^^^^^ true, no dash found
      #
      #   Note: we don't use semver,pattern={{raw}} because while that preserves the leading v in v1.2.3 it
      #   discards the leading v in v1.2.3-rc4.
      #
      # On push of a Git tag to refs/tags/v1.2.3-rc1 the Docker tags will be '<app>:v1.2.3' but NOT '<app>:latest'
      # because of:
      #   type=semver,pattern={{raw}}
      #   type=raw,value=latest,enable=${{ github.ref != 'refs/heads/main' && !contains(github.ref, '-') }}
      #                                    ^^^^^^^^^^^^^ true, not main       ^^^^^^^^^ false, dash found
      #
      # On push to Git refs/heads/main the Docker tag will be '<app>:unstable' because of:
      #   type=raw,value=unstable,enable=${{ github.ref == 'refs/heads/main' }}
      #
      # We set flavor latest=false to disable the default automatic output of a "latest" tag as there are cases
      # where a Git tag was pushed but we do NOT want to generate a "latest" tag, e.g. for release candidates,
      # instead we configure the docker/metadata-action with our own rule determining when to output a "latest"
      # tag.
      - name: Apply rules to Git metadata to generate potential Docker tags
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ inputs.docker_repo }}
          flavor: |
            latest=false
          tags: |
            type=semver,pattern={{version}},prefix=v
            type=raw,value=unstable,enable=${{ github.ref == 'refs/heads/main' }}
            type=raw,value=latest,enable=${{ github.ref != 'refs/heads/main' && !contains(github.ref, '-') }}
            type=raw,value=test,enable=${{ !contains(github.ref, 'refs/tags/v') && github.ref != 'refs/heads/main' }}

      # Encode values as base64 to avoid GitHub Actions refusing to pass the output on to the job that needs it with
      # warning "Skip output '...' since it may contain secret.". This can happen if the docker_org value contains the
      # DOCKER_HUB_ID value. E.g. if docker_org were 'nlnetlabs' and the user to login to Docker Hub as is also
      # 'nlnetlabs' then Docker thinks the latter, a secret, is being leaked via the workflow output defined above.
      # We disable output wrapping by the base64 command because the entire value of a key=value pair in the output
      # file must be on a single line, otherwise it results in an "Invalid format" error from GitHub Actions.
      - name: Encode outputs for passing safely to downstream jobs
        id: encode
        run: |
          ENCODED_ALL_REPO_AND_TAG_PAIRS=$(echo "${{ steps.meta.outputs.tags }}" | base64 --wrap=0)
          echo "all_repo_and_tag_pairs=${ENCODED_ALL_REPO_AND_TAG_PAIRS}" >> $GITHUB_OUTPUT

          ENCODED_FIRST_REPO_AND_TAG_PAIR=$(echo "${{ fromJSON(steps.meta.outputs.json).tags[0] }}" | base64 --wrap=0)
          echo "first_repo_and_tag_pair=${ENCODED_FIRST_REPO_AND_TAG_PAIR}" >> $GITHUB_OUTPUT

          ENCODED_LOWER_DOCKER_ORG=$(echo "${{ inputs.docker_org }}" | tr '[:upper:]' '[:lower:]' | base64 --wrap=0)
          echo "lower_docker_org=${ENCODED_LOWER_DOCKER_ORG}" >> $GITHUB_OUTPUT


  # -------------------------------------------------------------------------------------------------------------------
  # Job: 'cross'
  # -------------------------------------------------------------------------------------------------------------------
  # Cross-compiles packages in a separate job so that we can run it on the GitHub Actions runner host directly rather
  # than inside a Docker container (as is done by the `pkg` job below). We do this because we use `cargo cross` to
  # handle the complexity of using the right compile-time tooling and dependencies for cross compilation to work, and 
  # `cargo cross` works by launching its own Docker container. Trying to launch a Docker container from within a Docker
  # container, the so-called Docker-in-Docker scenario, is more difficult for `cargo cross` to handle correctly and
  # didn't work when I tried it, even with `CROSS_DOCKER_IN_DOCKER=true` set in the environment, hence this approach.
  #
  # See: https://github.com/rust-embedded/cross#docker-in-docker
  cross:
    if: ${{ needs.prepare.outputs.cross_build_rules != '{}' }}
    needs: prepare
    runs-on: ${{ fromJSON(needs.prepare.outputs.cross_runs_on) }}
    strategy:
      matrix: ${{ fromJSON(needs.prepare.outputs.cross_build_rules) }}
    steps:
    - name: Skip if no cross-compilation required
      id: skip
      run: |
        if [[ "${{ matrix.target }}" == "skip" ]]; then
          echo "skip=true" >> $GITHUB_OUTPUT
        else
          echo "skip=false" >> $GITHUB_OUTPUT
        fi

    - name: Checkout repository
      if: ${{ steps.skip.skip != 'true' }}
      uses: actions/checkout@v4

    # Install Rust the hard way rather than using a GH Action because the action doesn't work inside a Docker container.
    # Cargo cross "requires a rustup installation of Rust", an O/S package provided Rust won't
    - name: Install Rust
      if: ${{ steps.skip.skip != 'true' }}
      id: rust
      run: |
        case ${OS_NAME} in
          debian|ubuntu)
            apt-get update
            apt-get install -y curl
            ;;
        esac

        curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- --profile minimal -y
        echo "$HOME/.cargo/bin" >> $GITHUB_PATH
        source "$HOME/.cargo/env"
        echo "bin_dir=$HOME/.cargo/bin" >> $GITHUB_OUTPUT

    - name: Fetch cargo cross if available
      if: ${{ steps.skip.skip != 'true' }}
      id: cache-cargo-cross
      uses: actions/cache@v4
      with:
        path: |
          ${{ steps.rust.outputs.bin_dir }}/cross
          ${{ steps.rust.outputs.bin_dir }}/cross-util
        key: ${{ matrix.target }}-cargo-cross

    - name: Install cargo cross if needed
      id: install-cargo-cross
      if: ${{ steps.skip.skip != 'true' && steps.cache-cargo-cross.outputs.cache-hit != 'true' }}
      run: |
        cargo install cross
        echo "installed=true" >> $GITHUB_OUTPUT

    - name: Force cache save
      if: ${{ steps.skip.skip != 'true' && steps.install-cargo-cross.outputs.installed == 'true' }}
      uses: actions/cache/save@v4
      with:
        path: |
          ${{ steps.rust.outputs.bin_dir }}/cross
          ${{ steps.rust.outputs.bin_dir }}/cross-util
        key: ${{ matrix.target }}-cargo-cross

    - name: Ensure ~/.cargo/bin/ is in the path
      if: ${{ steps.skip.skip != 'true' }}
      run: |
        echo $(realpath ~/.cargo/bin) >> $GITHUB_PATH

    - name: Cross compile
      if: ${{ steps.skip.skip != 'true' }}
      run: |
        cross build ${{needs.prepare.outputs.cargo_manifest_path_arg}} ${{needs.prepare.outputs.cargo_workspace_package_arg}} --locked --release -v --target ${{ matrix.target }} ${{ inputs.cross_build_args }}

    - name: Tar the set of created binaries to upload
      if: ${{ steps.skip.skip != 'true' }}
      run: |
        rm -f bins.tar
        if [[ -z "${{ inputs.manifest_dir }}" ]]; then
          CROSS_FIND_BASE=.
        else
          CROSS_FIND_BASE="${{ inputs.manifest_dir }}"
        fi
        find "$CROSS_FIND_BASE/target/${{ matrix.target }}/release/" -maxdepth 1 -type f -executable | xargs tar vpcf bins.tar

    # Upload cross compiled binaries as GitHub Actions artifacts for use by the `pkg` job below. We can't use job
    # outputs as those are limited to 50 MB which we could easily exceed. We can't use actions/cache as cached items
    # are not necessarily available on different operating systems as the cache mechanism uses different namespaces
    # for different compression types and different compression types by operating system. As we don't want these
    # artifacts to be packaged by the scripts that upload to packages.nlnetlabs.nl we prefix the artifact name with
    # `tmp-` which will be ignored by packages.nlnetlabs.nl scripts.
    - name: Upload built binaries
      if: ${{ steps.skip.skip != 'true' }}
      uses: NLnetLabs/upload-artifact@main
      with:
        name: ${{ inputs.artifact_prefix }}tmp-cross-binaries-${{ matrix.target }}
        path: bins.tar
        if-no-files-found: warn

  # -------------------------------------------------------------------------------------------------------------------
  # Job: 'pkg'
  # -------------------------------------------------------------------------------------------------------------------
  # Use the cargo-deb and cargo-generate-rpm Rust crates to build Debian and RPM packages respectively for installing
  # our app. See:
  #   - https://github.com/mmstick/cargo-deb
  #   - https://github.com/cat-in-136/cargo-generate-rpm
  pkg:
    # Use of always() here ensures that even if the cross job is skipped we will still run
    if: ${{ always() && needs.prepare.outputs.package_build_rules != '{}' }}
    needs: prepare
    runs-on: ${{ fromJSON(needs.prepare.outputs.runs_on) }}
    # Build on the platform we are targeting in order to avoid https://github.com/rust-lang/rust/issues/57497.
    # Specifying container causes all of the steps in this job to run inside a Docker container (which is why the
    # cross-compilation needs to happen above in its own non-containerized job).
    container: ${{ matrix.image }}
    strategy:
      matrix: ${{ fromJSON(needs.prepare.outputs.package_build_rules) }}
    env:
      CARGO_DEB_VER: 4.0.0
      CARGO_GENERATE_RPM_VER: 0.16.1
      TOML_CLI_VER: 0.2.3
    steps:
    - name: Alma Linux GZIP workaround
      if: ${{ matrix.image == 'almalinux:10' }}
      run: |
        yum update -y
        yum install gzip -y

    - name: Checkout repository
      uses: actions/checkout@v3 # v4 doesn't work on containers with older GLIBC such as ubuntu:bionic or centos:7

    - name: Print matrix
      # Disable default use of bash -x for easier to read output in the log
      shell: bash
      run: |
        echo '${{ toJSON(matrix) }}'

    - name: Verify inputs
      id: verify
      run: |
        if [[ ! -f Cargo.toml ]]; then
          echo "::error::File 'Cargo.toml' is missing. This workflow is only intended for use with Rust Cargo projects."
          exit 1
        fi

        if [[ '${{ matrix.image }}' == '' ]]; then
          echo "::error::Required matrix variable 'image' is not defined in package_build_rules."
          exit 1
        fi

        if [[ '${{ matrix.target }}' == '' ]]; then
          echo "::error::Required matrix variable 'target' is not defined in package_build_rules."
          exit 1
        fi

        if [[ '${{ matrix.pkg }}' == '' ]]; then
          echo "pkg=${{ needs.prepare.outputs.cargo_name }}" >> $GITHUB_OUTPUT
        else
          echo "pkg=${{ matrix.pkg }}" >> $GITHUB_OUTPUT
        fi

    - name: Set vars
      id: setvars
      # Disable default use of bash -x for easier to read output in the log
      shell: bash
      env:
        MATRIX_IMAGE: ${{ matrix.image }}
        MATRIX_OS: ${{ matrix.os }}
      run: |
        # Get the operating system and release name (e.g. ubuntu and xenial) from the image name (e.g. ubuntu:xenial) by
        # extracting only the parts before and after but not including the colon:
        IMAGE="${MATRIX_IMAGE}"
        if [[ "${MATRIX_OS}" != "" ]]; then
          IMAGE="${MATRIX_OS}"
        fi

        if [[ "${IMAGE}" == "" ]]; then
          echo "::error::Matrix variable 'os' must be non-empty if set in package_build_rules."
          exit 1
        fi

        OS_NAME=${IMAGE%:*}
        OS_REL=${IMAGE#*:}

        if [[ "${OS_NAME}" == '' || "${OS_REL}" == '' ]]; then
          echo "::error::Matrix variable 'image' and/or 'os' must be of the form '<os name>:<os release>' in package_build_rules"
          exit 1
        fi

        case ${OS_NAME} in
          debian|ubuntu)
            ;;
          centos|rockylinux|almalinux)
            ;;
          *)
            echo "::error::This workflow only supports 'debian', 'ubuntu', 'centos', 'rockylinux' or 'almalinux' operating systems: '${IMAGE}' is not supported."
            exit 1
            ;;
        esac

        echo "OS_NAME=${IMAGE%:*}" >> $GITHUB_ENV
        echo "OS_REL=${IMAGE#*:}" >> $GITHUB_ENV

    # Allow CentOS 8 to continue working now that it is EOL
    # See: https://stackoverflow.com/a/70930049
    - name: CentOS 8 EOL workaround
      if: ${{ matrix.image == 'centos:8' }}
      run: |
        sed -i -e 's|mirrorlist=|#mirrorlist=|g' -e 's|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g' /etc/yum.repos.d/CentOS-Linux-*

    # See: https://github.com/NLnetLabs/ploutos
    # See: https://lists.debian.org/debian-devel-announce/2023/03/msg00006.html
    # See: https://unix.stackexchange.com/a/743865
    - name: Debian Stretch workaround
      if: ${{ matrix.image == 'debian:stretch' }}
      run: |
        echo "deb http://archive.debian.org/debian stretch main" > /etc/apt/sources.list
        echo "deb http://archive.debian.org/debian-security stretch/updates main" >> /etc/apt/sources.list

    # Install Rust the hard way rather than using a GH Action because the action doesn't work inside a Docker container.
    - name: Install Rust
      id: rust
      run: |
        case ${OS_NAME} in
          debian|ubuntu)
            apt-get update
            apt-get install -y curl
            ;;
        esac

        if ! hash cargo; then
          curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- --profile minimal -y
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH
          source "$HOME/.cargo/env"
          echo "bin_dir=$HOME/.cargo/bin" >> $GITHUB_OUTPUT
        else
          # Hack to determine the cargo install root directory so that we can tell the correct paths to actions/cache.
          # When using rustup to install Rust this is likely ~/.cargo/bin, but if using say the rust Docker image then
          # it is a different path entirely. The cargo command should already be installed so this should be almost a
          # no-op. Ideally it would be possible to just ask cargo but I haven't found a way. The docs list a 5-step
          # process for resolving the bin dir... (which involves checking --root, CARGO_INSTALL_ROOT, install.root,
          # CARGO_HOME and $HOME/.cargo...). Instead just find out where the cargo binary is installed and assume that
          # `cargo install` installed binaries will go there too.
          # See: https://doc.rust-lang.org/cargo/commands/cargo-install.html#description
          CARGO_BIN_DIR=$(dirname $(which cargo))
          echo "bin_dir=${CARGO_BIN_DIR}" >> $GITHUB_OUTPUT
        fi

    - name: Install compilation and other dependencies
      run: |
        case ${OS_NAME} in
          debian|ubuntu)
            apt-get install -y binutils gcc dpkg-dev jq lintian pkg-config ${{ inputs.deb_extra_build_packages }}
            ;;
          centos|rockylinux|almalinux)
            #sed -i -e 's/enabled=1/enabled=0/' /etc/yum/pluginconf.d/fastestmirror.conf || true
            yum update -y # See: https://github.com/NLnetLabs/ploutos/issues/90
            yum install epel-release -y
            yum install -y findutils gcc jq ${{ inputs.rpm_extra_build_packages }}

            # note: we also install python magic otherwise binaries are not identified as such and rpmlint outputs:
            #   E: no-binary
            case ${OS_REL} in
              7)
                yum install -y python-magic rpmlint
                ;;

              *)
                # assume we are only invoked with something newer than CentOS 7, e.g. not CentOS 6 ;-)
                yum install -y cpio python3-pip
                pip3 install --upgrade pip
                pip3 install python-magic rpmlint
                ;;
            esac
            ;;
        esac

    # Speed up Rust builds by caching unchanged built dependencies.
    # See: https://github.com/actions/cache/blob/master/examples.md#rust---cargo
    - name: Fetch .cargo from cache
      uses: actions/cache@v4
      with:
        path: |
          ~/.cargo/registry
          ~/.cargo/git
        key: ${{ matrix.image }}-${{ steps.verify.outputs.pkg }}-cargo-${{ hashFiles('**/Cargo.lock') }}

    # Speed up tooling installation by only re-downloading and re-building dependent crates if we change the version of
    # the tool that we are using.
    - name: Fetch cargo-deb from cache
      id: cache-cargo-deb
      uses: actions/cache@v4
      with:
        path: ${{ steps.rust.outputs.bin_dir }}/cargo-deb
        key: ${{ matrix.image }}-cargo-deb-${{ env.CARGO_DEB_VER }}-${{ endsWith(matrix.image, 'xenial')}}

    - name: Fetch cargo-generate-rpm from cache
      id: cache-cargo-generate-rpm
      uses: actions/cache@v4
      with:
        path: ${{ steps.rust.outputs.bin_dir }}/cargo-generate-rpm
        key: ${{ matrix.image }}-cargo-generate-rpm-${{ env.CARGO_GENERATE_RPM_VER }}

    - name: Fetch toml-cli from cache
      id: cache-toml-cli
      uses: actions/cache@v4
      with:
        path: ${{ steps.rust.outputs.bin_dir }}/toml
        key: ${{ matrix.image }}-toml-cli-${{ env.TOML_CLI_VER }}

    # Only install cargo-deb or cargo-generate-rpm if not already fetched from the cache.
    - name: Install cargo-deb if needed
      id: install-cargo-deb
      if: ${{ steps.cache-cargo-deb.outputs.cache-hit != 'true' }}
      run: |
        case ${OS_NAME} in
          debian|ubuntu)
            if [[ "${OS_REL}" == "xenial" ]]; then
              # Disable use of the default lzma feature which causes XZ compression to be used which then causes Lintian
              # to fail with error:
              #   E: krill: malformed-deb-archive newer compressed control.tar.xz
              # Passing --fast to cargo-deb to disable use of XZ compression didn't help.
              # See: https://github.com/kornelski/cargo-deb/issues/12
              EXTRA_CARGO_INSTALL_ARGS="--no-default-features"
            else
              EXTRA_CARGO_INSTALL_ARGS=""
            fi
            cargo install cargo-deb ${EXTRA_CARGO_INSTALL_ARGS} --git https://github.com/NLnetLabs/cargo-deb --branch usrmerge
            echo "installed=true" >> $GITHUB_OUTPUT
            ;;
        esac

    - name: Force cache save
      if: ${{ steps.install-cargo-deb.outputs.installed == 'true' }}
      uses: actions/cache/save@v4
      with:
        path: ${{ steps.rust.outputs.bin_dir }}/cargo-deb
        key: ${{ matrix.image }}-cargo-deb-${{ env.CARGO_DEB_VER }}-${{ endsWith(matrix.image, 'xenial')}}

    - name: Install cargo-generate-rpm if needed
      id: install-cargo-generate-rpm
      if: ${{ steps.cache-cargo-generate-rpm.outputs.cache-hit != 'true' }}
      run: |
        case ${OS_NAME} in
          centos|rockylinux|almalinux)
            cargo install cargo-generate-rpm --version ${CARGO_GENERATE_RPM_VER}
            echo "installed=true" >> $GITHUB_OUTPUT
            ;;
        esac

    - name: Force cache save
      if: ${{ steps.install-cargo-generate-rpm.outputs.installed == 'true' }}
      uses: actions/cache/save@v4
      with:
        path: ${{ steps.rust.outputs.bin_dir }}/cargo-generate-rpm
        key: ${{ matrix.image }}-cargo-generate-rpm-${{ env.CARGO_GENERATE_RPM_VER }}

    - name: Install toml-cli if needed
      id: install-toml-cli
      if: ${{ steps.cache-toml-cli.outputs.cache-hit != 'true' }}
      run: |
        cargo install toml-cli --version ${TOML_CLI_VER}
        echo "installed=true" >> $GITHUB_OUTPUT

    - name: Force cache save
      if: ${{ steps.install-toml-cli.outputs.installed == 'true' }}
      uses: actions/cache/save@v4
      with:
        path: ${{ steps.rust.outputs.bin_dir }}/toml
        key: ${{ matrix.image }}-toml-cli-${{ env.TOML_CLI_VER }}

    - name: Download cross-compiled binaries
      if: ${{ matrix.target != 'x86_64' }}
      uses: NLnetLabs/download-artifact@main
      with:
        name: ${{ inputs.artifact_prefix }}tmp-cross-binaries-${{ matrix.target }}
        path: .
        maxTries: ${{ needs.prepare.outputs.cross_max_tries }}
        retryDelayMs: ${{ needs.prepare.outputs.cross_retry_delay_ms }}
  
    - name: Untar the set of downloaded binaries
      if: ${{ matrix.target != 'x86_64' }}
      run: tar vpxf bins.tar

    # Instruct cargo-deb or cargo-generate-rpm to build the package based on Cargo.toml settings and command line
    # arguments.
    - name: Create the package
      id: create
      env:
        MATRIX_PKG: ${{ steps.verify.outputs.pkg }}
        EXTRA_BUILD_ARGS: ${{ matrix.extra_build_args }}
        EXTRA_CARGO_DEB_ARGS: ${{ matrix.extra_cargo_deb_args }}
        CROSS_TARGET: ${{ matrix.target }}
      run: |
        # Debian
        # ==============================================================================================================
        # Packages for different distributions (e.g. Stretch, Buster) of the same O/S (e.g. Debian) when served from a
        # single package repository MUST have unique package_ver_architecture triples. Cargo deb can vary the name based
        # on the 'variant' config section in use, but doesn't do so according to Debian policy (as it modifies the
        # package name, not the package version).
        #   Format: package_ver_architecture
        #   Where ver has format: [epoch:]upstream_version[-debian_revision]
        #   And debian_version should be of the form: 1<xxx>
        #   Where it is common to set <xxx> to the O/S name.
        # See:
        #   - https://unix.stackexchange.com/a/190899
        #   - https://www.debian.org/doc/debian-policy/ch-controlfields.html#version
        # Therefore we generate the version ourselves.
        #
        # In addition, Semantic Versioning and Debian version policy cannot express a pre-release label in the same way.
        # For example 0.8.0-rc.1 is a valid Cargo.toml [package].version value but when used as a Debian package version
        # 0.8.0-rc.1 would be considered _NEWER_ than the final 0.8.0 release. To express this in a Debian compatible
        # way we must replace the dash '-' with a tilda '~'.
        #
        # RPM
        # ==============================================================================================================
        # Handle the release candidate case where the version string needs to have dash replaced by tilda. The cargo
        # build command won't work if the version key in Cargo.toml contains a tilda but we have to put the tilda there
        # for when we run cargo generate-rpm so that it uses it.
        # 
        # For background on RPM versioning see:
        #   https://docs.fedoraproject.org/en-US/packaging-guidelines/Versioning/
        #
        # COMMON
        # ==============================================================================================================
        # Finally, sometimes we want a version to be NEWER than the latest release but without having to decide what
        # higher semver number to bump to. In this case we do NOT want dash '-' to become '~' because `-` is treated as
        # higher and tilda is treated as lower.

        if [[ '${{ matrix.image }}' == '' ]]; then
          echo "::error::Required matrix variable 'image' is not defined in package_build_rules."
          exit 1
        fi

        APP_VER=$(cargo read-manifest ${{ needs.prepare.outputs.cargo_read_manifest_path_arg }} | jq -r '.version')
        APP_NEW_VER=$(echo $APP_VER | tr '-' '~')
        NEXT_VER_LABEL="${{ inputs.next_ver_label }}"
        PKG_APP_VER=$(echo $APP_NEW_VER | sed -e "s/~$NEXT_VER_LABEL/-$NEXT_VER_LABEL/")

        TARGET_DIR="target"
        if [[ '${{ inputs.manifest_dir }}' != '' ]]; then
          TARGET_DIR="${{ inputs.manifest_dir }}/target"
        fi
        echo "target_dir=${TARGET_DIR}" >> $GITHUB_OUTPUT

        case ${OS_NAME} in
          debian|ubuntu)
            # Ugly hack to use an alternate base Cargo Deb configuration so that the selected variant overrides settings
            # in the specified alternate base settings instead of the usual [package.metadata.deb] base settings.
            if grep -Eq "^\[package\.metadata\.deb_alt_base_${MATRIX_PKG}\]$" ${{ needs.prepare.outputs.cargo_package_toml_path }}; then
              sed -i -e "s/^\[package\.metadata\.deb\]/[package.metadata.moved-deb]/" \
                     -e "s/^\[package\.metadata\.deb_alt_base_${MATRIX_PKG}\]/[package.metadata.deb]/" \
                     ${{ needs.prepare.outputs.cargo_package_toml_path }}
            fi

            VARIANT="${OS_NAME}-${OS_REL}"

            # Older O/S releases come with an older version of systemd which understands far fewer keys in the systemd
            # unit file. As such if we detect that we are installing to an older O/S we will use a "minimal" cargo-deb
            # profile, if one is defined in `Cargo.toml`.
            MINIMAL_VARIANT="minimal"

            # When cross-compiling we don't use cargo-deb to do compilation, only packaging, which means that cargo-deb is
            # not able to automatically determine install-time package dependencies for us (which happens if `depends` in
            # `Cargo.toml` is either empty or contains '$auto'). Instead the set of dependent packages must be specified
            # manually. The project being packaged can either define a cross-target specific `cargo-deb` profile, or a 
            # "minimal" profile suitable for cross-compiled targets.
            if [[ "${CROSS_TARGET}" != "x86_64" ]]; then
              EXTRA_CARGO_DEB_ARGS="--no-build --no-strip --target ${CROSS_TARGET} --output ${TARGET_DIR}/debian ${EXTRA_CARGO_DEB_ARGS}"
              MINIMAL_VARIANT="minimal-cross"
              VARIANT="${OS_NAME}-${OS_REL}-${CROSS_TARGET}"
            fi

            # Prefer the "minimal" cargo-deb profile, if one exists in `Cargo.toml`:
            if grep -qF "[package.metadata.deb.variants.${MINIMAL_VARIANT}]" ${{ needs.prepare.outputs.cargo_package_toml_path }}; then
                case ${OS_REL} in
                  xenial|bionic|stretch)
                    VARIANT="${MINIMAL_VARIANT}"
                    ;;
                esac
            fi

            OPT_VARIANT_ARG=""
            if [[ "${VARIANT}" != "" ]]; then
              if grep -qF "[package.metadata.deb.variants.${VARIANT}]" ${{ needs.prepare.outputs.cargo_package_toml_path }}; then
                OPT_VARIANT_ARG="--variant ${VARIANT}"
              else
                echo "::notice file=Cargo.toml::Cargo deb variant '${VARIANT}' not found, using defaults instead."
              fi
            fi

            CHANGELOG_KEY="package.metadata.deb.changelog"
            GEN_CHANGELOG_NAME="debian/changelog"
            GEN_CHANGELOG_PATH="${TARGET_DIR}/${GEN_CHANGELOG_NAME}"
            SET_CHANGELOG_PATH=$(toml get ${{ needs.prepare.outputs.cargo_package_toml_path }} ${CHANGELOG_KEY} || echo null)

            case ${SET_CHANGELOG_PATH} in
              null|'"'${GEN_CHANGELOG_PATH}'"')
                #
                # Generate the changelog file that Debian packages are required to have.
                # See: https://www.debian.org/doc/manuals/maint-guide/dreq.en.html#changelog
                #

                # 1. Use the same logic as cargo-deb, i.e. take the maintainer from the package.metadata.deb.maintainer
                #    key in Cargo.toml (for the selected variant) if defined, else use the first author instead.
                #
                # Note:
                #    With jq 1.6: del(..|nulls)
                #    With jq 1.5: del(recurse(.[]?;true)|select(. == null))
                #    Older systems only have jq 1.5 so we have to use the more verbose construct.
                V=${VARIANT:-null}
                MAINTAINER=$(cargo read-manifest ${{needs.prepare.outputs.cargo_read_manifest_path_arg}} | jq -r '[.metadata.deb.variants."'$V'".maintainer, .metadata.deb.maintainer, .authors[0]] | del(recurse(.[]?;true)|select(. == null))[0]')

                # 2. Generate the RFC 5322 format date by hand instead of using date --rfc-email because that option doesn't
                #    exist on Ubuntu 16.04 and Debian 9
                RFC5322_TS=$(LC_TIME=en_US.UTF-8 date +'%a, %d %b %Y %H:%M:%S %z')

                # 3. Generate the changelog file that Debian packages are required to have.
                if [ ! -d ${TARGET_DIR}/debian ]; then
                  mkdir -p ${TARGET_DIR}/debian
                fi
                echo "${MATRIX_PKG} (${PKG_APP_VER}) unstable; urgency=medium" > ${GEN_CHANGELOG_PATH}
                echo "  * See: https://github.com/${{ github.repository }}/releases/tag/v${APP_NEW_VER}" >> ${GEN_CHANGELOG_PATH}
                echo " -- maintainer ${MAINTAINER}  ${RFC5322_TS}" >> ${GEN_CHANGELOG_PATH}

                # 4. Print the generated changelog for diagnostic purposes
                echo "Generated changelog:"
                cat ${GEN_CHANGELOG_PATH}

                # 5. Configure cargo-deb to use the generated changelog file
                mv ${{ needs.prepare.outputs.cargo_package_toml_path }} ${{ needs.prepare.outputs.cargo_package_toml_path }}.org
                toml set \
                  ${{ needs.prepare.outputs.cargo_package_toml_path }}.org \
                  package.metadata.deb.changelog $(readlink -f ${GEN_CHANGELOG_PATH}) > \
                  ${{ needs.prepare.outputs.cargo_package_toml_path }}

                #
                # End changelog generation
                #
                ;;
            esac

            DEB_VER="${PKG_APP_VER}-1${OS_REL}"

            # This shouldn't be necessary...
            rm -f ${TARGET_DIR}/debian/*.deb

            cargo deb \
              ${{needs.prepare.outputs.cargo_manifest_path_arg}} \
              ${{needs.prepare.outputs.cargo_workspace_package_arg}} \
              --deb-version ${DEB_VER} \
              ${OPT_VARIANT_ARG} \
              -v ${EXTRA_CARGO_DEB_ARGS} \
              -- \
              --locked \
              ${EXTRA_BUILD_ARGS}
            ;;

          centos|rockylinux|almalinux)
            # Build and strip our app binaries as cargo generate-rpm doesn't do this for us
            cargo build \
              ${{needs.prepare.outputs.cargo_manifest_path_arg}} \
              ${{needs.prepare.outputs.cargo_workspace_package_arg}} \
              --release \
              --locked \
              -v \
              ${EXTRA_BUILD_ARGS}

            # TODO: It might be possible to replace the hacky copying of the service file below with some clever use of
            # `--set-metadata` when invoking cargo generate-rpm. Of particular interest is the new `--variant` command
            # line argument which might enable us to work the same way as we do for cargo deb above.
            # See: https://github.com/cat-in-136/cargo-generate-rpm/issues/18

            ## Determine any additional arguments that need to be passed to cargo generate-rpm
            #case "${OS_NAME}:${OS_REL}" in
            #  centos:7)
            #    # yum install fails on older CentOS with the default LZMA compression used by cargo generate-rpm since v0.5.0
            #    # see: https://github.com/cat-in-136/cargo-generate-rpm/issues/30
            #    EXTRA_CARGO_GENERATE_RPM_ARGS="--payload-compress gzip"
            #    ;;
            #  *)
            #    # assume we are only invoked with something newer than CentOS 7, e.g. not CentOS 6 ;-)
            #    EXTRA_CARGO_GENERATE_RPM_ARGS=""
            #    ;;
            #esac

            # Hack to use a different service file without having to duplicate almost the entire 
            # [package.metadata.generate-rpm.assets] setting with only one entry changed. We don't need this with
            # cargo-deb because it handles systemd service file selection automatically based on factors like the
            # current variant in use.

            # Support the older matrix variable name for backward compatibility.
            if [[ "${{ matrix.rpm_systemd_service_unit_file }}" != "" ]]; then
                SYSTEMD_SERVICE_UNIT_FILE="${{ matrix.rpm_systemd_service_unit_file }}"
            else
                SYSTEMD_SERVICE_UNIT_FILE="${{ matrix.systemd_service_unit_file }}"
            fi

            if [ -e "${SYSTEMD_SERVICE_UNIT_FILE}" ]; then
                mkdir -p ${TARGET_DIR}/rpm/
                # Parse the Debian SystemD script file naming which the user may have used for input to cargo-deb
                # but which we will then also have to deal with as well:
                #   <package>.<unit>.<script> - strip out <package> and use the rest
                #   <package.<script>         - use as-is
                #   <unit>.<script>           - use as-is
                #   <script>                  - use as-is
                if [[ "${SYSTEMD_SERVICE_UNIT_FILE}" =~ ^[^.]+\.([^.]+\.[^.]+)$ ]]; then
                    cp ${SYSTEMD_SERVICE_UNIT_FILE} ${TARGET_DIR}/rpm/${BASH_REMATCH[1]}
                else
                    cp ${SYSTEMD_SERVICE_UNIT_FILE} ${TARGET_DIR}/rpm/
                fi
            elif [[ "${SYSTEMD_SERVICE_UNIT_FILE}" == *"*" ]]; then
                mkdir -p ${TARGET_DIR}/rpm/
                cp ${SYSTEMD_SERVICE_UNIT_FILE} ${TARGET_DIR}/rpm
            fi

            # Ugly hack to use an alternate base Cargo Generate RPM configuration so that the selected variant overrides
            # settings specified alternate base settings instead of the usual [package.metadata.generate-rpm] base
            # settings.
            RPM_SCRIPTLETS_PATH="${{ inputs.rpm_scriptlets_path }}"
            if grep -Eq "^\[package\.metadata\.generate-rpm-alt-base-${MATRIX_PKG}\]$" ${{ needs.prepare.outputs.cargo_package_toml_path }}; then
              if [[ "${RPM_SCRIPTLETS_PATH}" != "" ]]; then
                RPM_SCRIPTLETS_PATH="${RPM_SCRIPTLETS_PATH}-${MATRIX_PKG}"
              fi
              sed -i -e "s/^\[package\.metadata\.generate-rpm\]/[package.metadata.moved-generate-rpm]/" \
                     -e "s/^\[package\.metadata\.generate-rpm-alt-base-${MATRIX_PKG}\]/[package.metadata.generate-rpm]/" \
                     ${{ needs.prepare.outputs.cargo_package_toml_path }}
            fi

            # If the manifest_dir is set, we will change the working directory down
            # below. Therfore, we need to create a path to the scriptlets file that
            # is relative to that working directory instead of the git repo's root.
            if [[ -n "${{ inputs.manifest_dir }}" && -f "${RPM_SCRIPTLETS_PATH}" ]]; then
              MANIFEST_RELATIVE_SCRIPTLETS_PATH=$(realpath --relative-to "${{ inputs.manifest_dir }}" "${RPM_SCRIPTLETS_PATH}")
            fi

            # https://github.com/NLnetLabs/krill/issues/907
            # cargo-generate-rpm doesn't support setting scripts to files, and we can't refer to a file that 
            # installed such as /usr/share/krill/rpm/postuninst because 'yum remove' removes the file before it
            # can be executed (hence post-uninstall rather than pre-uninstall...). So instead embed the entire
            # uninstall script in the TOML settings using the cargo-generate-rpm --set-metadata (aka -s)
            # command line argument.
            if [ -f "${RPM_SCRIPTLETS_PATH}" ]; then
              # Download the RPM systemd macros shell functions file fragment
              SYSTEMD_RPM_MACROS_URL="https://raw.githubusercontent.com/NLnetLabs/ploutos/v9.0.2/fragments/macros.systemd.sh"
              SYSTEMD_RPM_MACROS_FILE="/tmp/systemd_rpm_macros"
              curl --proto '=https' --tlsv1.2 --fail --output ${SYSTEMD_RPM_MACROS_FILE} ${SYSTEMD_RPM_MACROS_URL}

              # Bash 5.2 introduced the option patsub_replacement, which makes pattern substitution replace
              # all occurances of `&` in the replacement string ($value in the case below) with the matched pattern
              # (#RPM_SYSTEMD_MACROS# in the case below). The following line disables that behavior, if that option exists.
              shopt | grep -q "^patsub_replacement" && shopt -u patsub_replacement

              # Replace any reference to #SYSTEMD_RPM_MACROS# in the scriptlet file with the downloaded RPM systemd macros
              # shell fragment.
              SCRIPTLET_FILE="${{ inputs.rpm_scriptlets_path }}"
              mv "${SCRIPTLET_FILE}" "${SCRIPTLET_FILE}.org"
              templ=$(<${SCRIPTLET_FILE}.org)
              value=$(<$SYSTEMD_RPM_MACROS_FILE)
              echo "${templ//#RPM_SYSTEMD_MACROS#/$value}" > "$SCRIPTLET_FILE"

              # Configure ourselves to use the updated scriptlets file as input to cargo generate-rpm.
              if [[ -n "$MANIFEST_RELATIVE_SCRIPTLETS_PATH" ]]; then
                SCRIPTLETS="--metadata-overwrite=$MANIFEST_RELATIVE_SCRIPTLETS_PATH"
              else
                SCRIPTLETS='--metadata-overwrite=${{ inputs.rpm_scriptlets_path }}'
              fi
            fi

            find ${TARGET_DIR}/release -maxdepth 1 -type f -executable | xargs strip -s -v

            # This shouldn't be necessary...
            rm -f ${TARGET_DIR}/generate-rpm/*.rpm

            if [[ '${{inputs.manifest_dir}}' != '' ]]; then
              pushd ${{inputs.manifest_dir}}
            fi
  
            cargo generate-rpm ${{needs.prepare.outputs.cargo_workspace_package_arg}} \
                --set-metadata "version=\"${PKG_APP_VER}\"" \
                ${SCRIPTLETS} \
                ${EXTRA_CARGO_GENERATE_RPM_ARGS}

            if [[ '${{inputs.manifest_dir}}' != '' ]]; then
              popd
            fi

            ;;
        esac

    - name: Post-process the package
      run: |
        TARGET_DIR="${{ steps.create.outputs.target_dir}}"

        case ${OS_NAME} in
          debian|ubuntu)
            # https://github.com/NLnetLabs/routinator/issues/783
            # Patch the generated DEB to have ./ paths compatible with `unattended-upgrade`:
            ls -la ${TARGET_DIR}/debian/

            pushd ${TARGET_DIR}/debian
            DEB_FILE_NAME=$(ls -1 *.deb | head -n 1)
            DATA_ARCHIVE=$(ar t ${DEB_FILE_NAME} | grep -E '^data\.tar')
            ar x ${DEB_FILE_NAME} ${DATA_ARCHIVE}
            tar tf ${DATA_ARCHIVE}
            EXTRA_TAR_ARGS=
            if [[ "${DATA_ARCHIVE}" == *.xz ]]; then
              # Install XZ support that will be needed by TAR
              apt-get -y install -y xz-utils
              EXTRA_TAR_ARGS=J
            fi
            mkdir tar-hack
            tar -C tar-hack -xf ${DATA_ARCHIVE}
            pushd tar-hack
            tar c${EXTRA_TAR_ARGS}f ../${DATA_ARCHIVE} ./*
            popd
            tar tf ${DATA_ARCHIVE}
            ar r ${DEB_FILE_NAME} ${DATA_ARCHIVE}
            popd

            ls -la ${TARGET_DIR}/debian/

            pushd ${TARGET_DIR}/debian
            dpkg -e ${DEB_FILE_NAME} control_files
            dpkg -x ${DEB_FILE_NAME} data_files

            for D in control_files data_files; do
              pushd $D

              echo Listing package $D and sizes
              find . -type f -exec du -sh {} \;

              echo
              echo Printing non-binary files contained within $D

              # Use grep to exclude find only non-binary files that we can print
              find . -type f -exec grep -Il '.' {} \; -exec cat {} \; -exec echo \; -exec echo \;

              popd
              rm -R $D
            done
            popd
            ;;

          centos|rockylinux|almalinux)
            ls -la ${TARGET_DIR}/generate-rpm/

            pushd ${TARGET_DIR}/generate-rpm
            for F in *.rpm; do
              echo Printing package info
              rpm -qip $F
  
              echo $F
              mkdir t
              pushd t
              rpm2cpio ../$F | cpio -idmv || true

              echo Listing package files and sizes
              find . -type f -exec du -sh {} \;

              echo
              echo Printing non-binary files contained within the package

              # Use grep to exclude find only non-binary files that we can print
              find . -type f -exec grep -Il '.' {} \; -exec cat {} \; -exec echo \; -exec echo \;

              popd
              rm -R t

              echo Printing package scriptlets
              rpm -qp --scripts $F
            done

            popd
            ;;
        esac

    # See what O/S specific linting tools think of our package.
    - name: Verify the package
      env:
        CROSS_TARGET: ${{ matrix.target }}
      run: |
        TARGET_DIR="${{ steps.create.outputs.target_dir}}"
        if [[ '${{ inputs.manifest_dir }}' != '' ]]; then
          TARGET_DIR="${{ inputs.manifest_dir }}/target"
        fi

        case ${OS_NAME} in
          debian|ubuntu)
            dpkg --info ${TARGET_DIR}/debian/*.deb

            EXTRA_LINTIAN_ARGS="${{ matrix.deb_extra_lintian_args }}"
            EXTRA_LINTIAN_ARGS="${EXTRA_LINTIAN_ARGS} --suppress-tags manpage-not-compressed-with-max-compression"

            case ${OS_REL} in
              xenial|bionic|focal|stretch|buster)
                ;;

              *)
                EXTRA_LINTIAN_ARGS="${EXTRA_LINTIAN_ARGS} --suppress-tags poor-compression-in-manual-page"
                ;;
            esac

            if [[ "${CROSS_TARGET}" != "x86_64" ]]; then
              EXTRA_LINTIAN_ARGS="${EXTRA_LINTIAN_ARGS} --suppress-tags unstripped-binary-or-object,statically-linked-binary"
            fi

            if [[ "${{ inputs.strict_mode }}" == "true" ]]; then
              case ${OS_REL} in
                focal)
                  ;;

                xenial|bionic|stretch|buster)
                  EXTRA_LINTIAN_ARGS="${EXTRA_LINTIAN_ARGS} --fail-on-warnings"
                  ;;

                *)
                  EXTRA_LINTIAN_ARGS="${EXTRA_LINTIAN_ARGS} --fail-on error,warning"
                  ;;
              esac
            else
              case ${OS_REL} in
                xenial|bionic|focal|stretch|buster)
                  ;;

                *)
                  EXTRA_LINTIAN_ARGS="${EXTRA_LINTIAN_ARGS} --fail-on error"
                  ;;
              esac
            fi

            lintian --version
            lintian --allow-root -v ${EXTRA_LINTIAN_ARGS} ${TARGET_DIR}/debian/*.deb
            ;;

          centos|rockylinux|almalinux)
            # cargo generate-rpm creates RPMs that rpmlint considers to have errors so don't use the rpmlint exit code
            # otherwise we will always abort the workflow.

            # rpmlint checks are failing that relate to "tags" that cargo-generate-rpm does not currently support
            # setting. The only way to disable certain checks is by writing a config file to disk. At the time of
            # writing versions of rpmlint encountered were:
            #
            #    centos:7 Docker image    : rpmlint 1.5
            #    almalinux:8 Docker image: rpmlint 1.10
            #    almalinux:8 Docker image: rpmlint 2.4.0 (via pip3 install rpmlint)
            #    fedora:37 Docker image:    rpmlint 2.2.0
            #
            # CentOS / almalinux 8 supports rpmlint 2.x via python3-pip, so we can use the newer version instead, but
            # this can't be installed on CentOS 7 due to a missing rpm-python3 RPM bindings package needed by pip3
            # install.
            #
            # See: https://github.com/rpm-software-management/rpmlint/blob/2.4.0/README.md#configuration
            # See: https://github.com/rpm-software-management/rpmlint/blob/rpmlint-1.4/README#L39
            # See: https://github.com/cat-in-136/cargo-generate-rpm/issues/20

            EXTRA_RPMLINT_ARGS=
            LINTER_CONFIG_PATH="$HOME/.config/rpmlint"

            #case ${OS_REL} in
            #  7)
            #    # On CentOS 7 we only have the older rpmlint 1.x available, which has a known issue with the
            #    # `missing-call-to-chdir-with-chroot` check causing false positives, therefore we filter this error
            #    # out. The false positive issue was fixed in rpmlint 2.x.
            #    #
            #    # See: https://github.com/rpm-software-management/rpmlint/issues/84
            #    mkdir $HOME/.config
            #    cat <<'EOF' >${LINTER_CONFIG_PATH}
            #    from Config import *
            #    addFilter(".: no-buildhost-tag")
            #    addFilter(".: no-changelogname-tag")
            #    addFilter(".: missing-call-to-chdir-with-chroot")
            #    EOF
            #    ;;

            #  *)
                # Assume we are only invoked with something newer than CentOS 7, e.g. not CentOS 6 ;-)
                if [[ "${{ inputs.strict_mode }}" == "true" ]]; then
                  EXTRA_RPMLINT_ARGS="${EXTRA_RPMLINT_ARGS} --strict"
                fi

                mkdir $HOME/.config
                cat <<'EOF' >${LINTER_CONFIG_PATH}
        addFilter(".: no-buildhost-tag")
        addFilter(".: no-changelogname-tag")
        addFilter(".: no-group-tag")
        addFilter(".: no-packager-tag")
        addFilter(".: no-signature")
        EOF

                # rpmlint 2.x requires that we explicitly tell it where the config file is, and the pip installed
                # version doesn't come with any existing list of valid licenses so we have to install one ourselves.
                # With rpmlint 1.x, or rpmlint 2.x installed from O/S package (e.g. on fedora:37) the valid license
                # set is pre-loaded, but that doesn't help us here. If we don't solve this a warning, or error in
                # strict mode, will be raised about the unknown license used by the RPM being checked (as all
                # licenses are unknown!).
                LICENSES_CONF_URL="https://raw.githubusercontent.com/rpm-software-management/rpmlint/2.4.0/configs/Fedora/licenses.toml"
                LICENSES_CONF_PATH="$HOME/.config/rpmlint-licenses.conf"
                curl --proto '=https' --tlsv1.2 --fail --output ${LICENSES_CONF_PATH} ${LICENSES_CONF_URL}

                EXTRA_RPMLINT_ARGS="${EXTRA_RPMLINT_ARGS} --rpmlintrc ${LINTER_CONFIG_PATH} --config ${LICENSES_CONF_PATH}"
            #    ;;
            #esac

            for CHECK_NAME in ${{ matrix.rpm_rpmlint_check_filters }}; do
              echo 'addFilter(".: '${CHECK_NAME}'")' >> ${LINTER_CONFIG_PATH}
            done

            cat ${LINTER_CONFIG_PATH}

            rpmlint --version
            rpmlint ${EXTRA_RPMLINT_ARGS} ${TARGET_DIR}/generate-rpm/*.rpm
            ;;
        esac

    # Upload the produced package. The artifact will be available via the GH Actions job summary and build log pages,
    # but only to users logged in to GH with sufficient rights in this project. The uploaded artifact is also downloaded
    # by the next job (see below) to sanity check that it can be installed and results in a working Krill installation.
    - name: Upload package
      uses: NLnetLabs/upload-artifact@main
      with:
        name: ${{ inputs.artifact_prefix }}${{ steps.verify.outputs.pkg }}_${{ env.OS_NAME }}_${{ env.OS_REL }}_${{ matrix.target }}
        path: |
          ${{ steps.create.outputs.target_dir }}/debian/*.deb
          ${{ steps.create.outputs.target_dir }}/generate-rpm/*.rpm
        if-no-files-found: warn

  # -------------------------------------------------------------------------------------------------------------------
  # Job: 'pkg-test'
  # -------------------------------------------------------------------------------------------------------------------
  # Download and sanity check on target operating systems the packages created by previous jobs (see above). Don't test
  # on GH runners as they come with lots of software and libraries pre-installed and thus are not representative of the
  # actual deployment targets, nor do GH runners support all targets that we want to test. Don't test in Docker
  # containers as they do not support systemd.
  pkg-test:
    # Use of always() here ensures that even if the _cross_ job (note: not the 'pkg' job) is skipped we will still run.
    # I wouldn't expect this to be needed but since the cross job was made conditional we seem to need this.
    if: ${{ always() && needs.prepare.outputs.package_test_rules != '{}' }}
    needs: [pkg, prepare]
    # If runs_on is not overridden by the user, and we are about to test a package in a CentOS 7 LXC container, force
    # the host O/S to be the older Ubuntu 20.04 as Ubuntu 22.04 upgraded from CGroupV1 to CGroupV2 which is incompatible
    # with the CentOS 7 LXC image. Use a sort-of ternary if syntax that GitHub Actions supports in expressions to effect
    # this dynamically per matrix invocation of the `pkg-test` job.
    # See:
    #   - https://github.com/NLnetLabs/ploutos/issues/50
    #   - https://github.com/actions/runner/issues/409#issuecomment-727565588
    runs-on: ${{ (inputs.runs_on == 'ubuntu-22.04' && (matrix.image == 'centos:7' || matrix.image == 'ubuntu:xenial')) && 'ubuntu-20.04' || inputs.runs_on }}
    strategy:
      fail-fast: false
      matrix: ${{ fromJSON(needs.prepare.outputs.package_test_rules) }}
    steps:
    # Fetch the test scripts that we will run
    - name: Checkout repository
      uses: actions/checkout@v3 # v4 doesn't work on containers with older GLIBC such as ubuntu:bionic or centos:7

    - name: Print matrix
      # Disable default use of bash -x for easier to read output in the log
      shell: bash
      run: |
        echo '${{ toJSON(matrix) }}'

    - name: Verify inputs
      id: verify
      run: |
        if [[ '${{ matrix.image }}' == '' ]]; then
          echo "::error::Required matrix variable 'image' is not defined in package_test_rules."
          exit 1
        fi

        if [[ '${{ matrix.target }}' == '' ]]; then
          echo "::error::Required matrix variable 'target' is not defined in package_test_rules."
          exit 1
        fi

        if [[ '${{ matrix.pkg }}' == '' ]]; then
          echo "pkg=${{ needs.prepare.outputs.cargo_name }}" >> $GITHUB_OUTPUT
        else
          echo "pkg=${{ matrix.pkg }}" >> $GITHUB_OUTPUT
        fi

        if [[ '${{ matrix.published_pkg }}' == '' ]]; then
          PUBLISHED_PKG="${{ matrix.pkg }}"
        else
          PUBLISHED_PKG="${{ matrix.published_pkg }}"
        fi
        echo "published_pkg=$PUBLISHED_PKG" >> $GITHUB_OUTPUT

        if [[ '${{ matrix.mode }}' == '' ]]; then
          echo "mode=fresh-install" >> $GITHUB_OUTPUT
        else
          echo "mode=${{ matrix.mode }}" >> $GITHUB_OUTPUT
        fi

        if [[ '${{ matrix.os }}' == '' ]]; then
          echo "image=${{ matrix.image }}" >> $GITHUB_OUTPUT
        else
          echo "image=${{ matrix.os }}" >> $GITHUB_OUTPUT
        fi

        if [[ '${{ matrix.deb_apt_key_url }}' != '' ]]; then
          DEB_APT_KEY_URL='${{ matrix.deb_apt_key_url }}'
        elif [[ '${{ inputs.deb_apt_key_url }}' != '' ]]; then
          DEB_APT_KEY_URL='${{ inputs.deb_apt_key_url }}'
        else
          DEB_APT_KEY_URL='https://packages.nlnetlabs.nl/aptkey.asc'
        fi
        echo "deb_apt_key_url=$DEB_APT_KEY_URL" >> $GITHUB_OUTPUT

        if [[ '${{ matrix.deb_apt_source }}' != '' ]]; then
          DEB_APT_SOURCE='${{ matrix.deb_apt_source }}'
        elif [[ '${{ inputs.deb_apt_source }}' != '' ]]; then
          DEB_APT_SOURCE='${{ inputs.deb_apt_source }}'
        else
          DEB_APT_SOURCE='deb [arch=amd64] https://packages.nlnetlabs.nl/linux/${OS_NAME}/ ${OS_REL} main'
        fi
        echo "deb_apt_source=$DEB_APT_SOURCE" >> $GITHUB_OUTPUT

        if [[ '${{ matrix.rpm_yum_key_url }}' != '' ]]; then
          RPM_YUM_KEY_URL='${{ matrix.rpm_yum_key_url }}'
        elif [[ '${{ inputs.rpm_yum_key_url }}' != '' ]]; then
          RPM_YUM_KEY_URL='${{ inputs.rpm_yum_key_url }}'
        else
          RPM_YUM_KEY_URL="https://packages.nlnetlabs.nl/aptkey.asc"
        fi
        echo "rpm_yum_key_url=$RPM_YUM_KEY_URL" >> $GITHUB_OUTPUT

        # See: https://docs.github.com/en/actions/writing-workflows/choosing-what-your-workflow-does/workflow-commands-for-github-actions#multiline-strings
        echo 'rpm_yum_repo<<EOF' >> "$GITHUB_OUTPUT"
        {
          if [[ '${{ matrix.rpm_yum_repo }}' != '' ]]; then
            echo '${{ matrix.rpm_yum_repo }}'
          elif [[ '${{ inputs.rpm_yum_repo }}' != '' ]]; then
            echo '${{ inputs.rpm_yum_repo }}'
          else
            cat <<'EOF'
        [nlnetlabs]
        name=NLnet Labs
        baseurl=https://packages.nlnetlabs.nl/linux/centos/$releasever/main/$basearch
        enabled=1
        EOF
          fi
        } >> "$GITHUB_OUTPUT"
        echo EOF >> "$GITHUB_OUTPUT"

        if [[ '${{ matrix.rpm_yum_extra_args }}' != '' ]]; then
          echo 'rpm_yum_extra_args=${{ matrix.rpm_yum_extra_args }}' >> $GITHUB_OUTPUT
        elif [[ '${{ inputs.rpm_yum_extra_args }}' != '' ]]; then
          echo 'rpm_yum_extra_args=${{ inputs.rpm_yum_extra_args }}' >> $GITHUB_OUTPUT
        fi

    # Set some environment variables that will be available to "run" steps below in this job, and some output variables
    # that will be available in GH Action step definitions below.
    - name: Set vars
      id: setvars
      # Disable default use of bash -x for easier to read output in the log
      shell: bash
      env:
        MATRIX_IMAGE: ${{ steps.verify.outputs.image }}
      run: |
        # Get the operating system and release name (e.g. ubuntu and xenial) from the image name (e.g. ubuntu:xenial) by
        # extracting only the parts before and after but not including the colon:
        OS_NAME=${MATRIX_IMAGE%:*}
        OS_REL=${MATRIX_IMAGE#*:}

        if [[ "${OS_NAME}" == '' || "${OS_REL}" == '' ]]; then
          echo "::error::Matrix variable 'image' must be of the form '<os name>:<os release>' in package_test_rules"
          exit 1
        fi

        echo "OS_NAME=${OS_NAME}" >> $GITHUB_ENV
        echo "OS_REL=${OS_REL}" >> $GITHUB_ENV

        if [[ '${{ matrix.test-image }}' != '' ]]; then
          # convert os_name:os_rel to os_name/os_rel. The colon form is consistent with the values the user must
          # otherwise provide as input, e.g. via the 'image' matrix entry, but LXC images separate the image name
          # from the image release using a forward slash rather than a colon so we have to convert.
          TEST_IMAGE="${{ matrix.test-image }}"
          LXC_IMAGE_NAME=${TEST_IMAGE%:*}
          LXC_IMAGE_REL=${TEST_IMAGE#*:}
          echo "LXC_IMAGE=images:${LXC_IMAGE_NAME}/${LXC_IMAGE_REL}/cloud" >> $GITHUB_ENV
        else
          case ${MATRIX_IMAGE} in
            centos:8)
              # the CentOS 8 LXD image no longer exists since CentOS 8 hit EOL.
              # use the Rocky Linux (a CentOS 8 compatible O/S) LXD image instead.
              echo "LXC_IMAGE=images:almalinux/8/cloud" >> $GITHUB_ENV
              ;;
            *)
              echo "LXC_IMAGE=images:${OS_NAME}/${OS_REL}/cloud" >> $GITHUB_ENV
              ;;
          esac
        fi

    - name: Download package
      uses: actions/download-artifact@v4
      with:
        name: ${{ inputs.artifact_prefix }}${{ steps.verify.outputs.pkg }}_${{ env.OS_NAME }}_${{ env.OS_REL }}_${{ matrix.target }}

    - name: Install Incus
      run: |
        # pre ubuntu-24.04
        sudo mkdir -p /etc/apt/keyrings/
        sudo curl -fsSL https://pkgs.zabbly.com/key.asc -o /etc/apt/keyrings/zabbly.asc
        sudo sh -c 'cat <<EOF > /etc/apt/sources.list.d/zabbly-incus-lts-6.0.sources
        Enabled: yes
        Types: deb
        URIs: https://pkgs.zabbly.com/incus/lts-6.0
        Suites: $(. /etc/os-release && echo ${VERSION_CODENAME})
        Components: main
        Architectures: $(dpkg --print-architecture)
        Signed-By: /etc/apt/keyrings/zabbly.asc

        EOF'
        sudo apt-get update
        sudo apt-get install -y incus

    # Fix iptables so that LXC containers can connect out after Docker sets FORWARD to DROP by default
    # https://discuss.linuxcontainers.org/t/lxd-losts-iptables-rules-with-docker/15045/6.
    # This wasn't needed with Ubuntu 20.04 but is needed with Ubuntu 22.04.
    - name: Fix firewall for LXD
      run: |
        # This issue seems to affect various newer O/S's and the fix seems to be harmless on older O/S's, so we don't
        # bother trying to be clever about O/S version based logic but just do this for all hosts.
        sudo iptables -I DOCKER-USER -i incusbr0 -j ACCEPT
        sudo iptables -I DOCKER-USER -o incusbr0 -j ACCEPT

    - name: Add current user to LXD group
      run: |
        sudo usermod --append --groups incus $(whoami)

    - name: Initialize LXD
      run: |
        sudo incus admin init --auto

    - name: Check LXD configuration
      run: |
        sudo incus info

    # Use of IPv6 sometimes prevents yum update being able to resolve mirrorlist.centos.org.
    - name: Disable LXD assignment of IPv6 addresses
      run: |
        sudo incus network set incusbr0 ipv6.address none

    - name: Launch LXC container
      run: |
        # security.nesting=true is needed to avoid error "Failed to set up mount namespacing: Permission denied" in a
        # Debian 10 container.
        sudo incus launch ${LXC_IMAGE} -c security.nesting=true -c environment.DEBIAN_FRONTEND=noninteractive testcon

    # Run package update and install man and sudo support (missing in some LXC/LXD O/S images) but first wait for
    # cloud-init to finish otherwise the network isn't yet ready. Don't use cloud-init status --wait as that isn't
    # supported on older O/S's like Ubuntu 16.04 and Debian 9. Use the sudo package provided configuration files
    # otherwise when using sudo we get an error that the root user isn't allowed to use sudo.
    - name: Prepare container
      run: |
        echo "Waiting for cloud-init.."
        SUCCESS=0
        for i in $(seq 1 60); do
          if sudo incus exec testcon -- ls -la /var/lib/cloud/data/result.json; then
            SUCCESS=1
            break
          else
          sleep 1s
          fi
        done

        # Log the cloud-init result file for diagnostic purposes
        sudo incus exec testcon -- cat /var/lib/cloud/data/result.json || true

        if [ $SUCCESS -eq 0 ]; then
          sudo incus exec testcon -- ls -la /var/lib/ || true
          sudo incus exec testcon -- ls -lR /var/lib/cloud || true
          sudo incus exec testcon -- ls -lR /usr/lib/systemd/system/ || true
          sudo incus exec testcon -- ls -lR /etc/cloud/ || true
          sudo incus exec testcon -- find /etc/cloud -type f -print -exec cat {} \; || true
          sudo incus exec testcon -- cloud-init status || true
          sudo incus exec testcon -- systemctl status cloud-init || true
          sudo incus exec testcon -- systemctl || true
          sudo incus exec testcon -- journalctl -u cloud-init || true
          sudo incus exec testcon -- journalctl || true
          sudo incus exec testcon -- find /var/log/ -type f -iname '*cloud*' -print -exec cat {} \;
          # try and continue anyway...
          echo "::warning::Unable to detect completion of cloud-init, subsequent steps may encounter unexpected failures. Check the logs just before this line."
        fi

        case ${OS_NAME} in
          debian|ubuntu)
            sudo incus exec testcon -- apt-get update
            sudo incus exec testcon -- apt-get install -y -o Dpkg::Options::="--force-confnew" apt-transport-https ca-certificates man sudo wget
            ;;
          centos|rockylinux|almalinux)
            if [[ "${MATRIX_IMAGE}" == "centos:8" ]]; then
              # allow CentOS 8 to continue working now that it is EOL
              # see: https://stackoverflow.com/a/70930049
              sudo incus exec testcon -- find /etc/yum.repos.d/ -name 'CentOS-Linux-*' -exec sed -i -e 's|mirrorlist=|#mirrorlist=|g' -e 's|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g' {} \;
            fi
            sudo incus exec testcon -- yum install -y man
            ;;
        esac

    - name: Copy the newly built package into the LXC container
      run: |
        case ${OS_NAME} in
          debian|ubuntu)
            DEB_FILE=$(ls -1 debian/*.deb)
            sudo incus file push ${DEB_FILE} testcon/tmp/
            echo "PKG_FILE=$(basename $DEB_FILE)" >> $GITHUB_ENV
            ;;
          centos|rockylinux|almalinux)
            RPM_FILE=$(ls -1 generate-rpm/*.rpm)
            sudo incus file push ${RPM_FILE} testcon/tmp/
            echo "PKG_FILE=$(basename $RPM_FILE)" >> $GITHUB_ENV
            ;;
        esac

    - name: Configure extra package repo
      if: ${{ steps.verify.outputs.mode == 'upgrade-from-published'  || inputs.package_test_always_add_repo }}
      run: |
        case ${OS_NAME} in
          debian|ubuntu)
            if [[ -f '${{ steps.verify.outputs.deb_apt_source }}' ]]; then
              sudo incus file push ${{ steps.verify.outputs.deb_apt_source }} testcon/etc/apt/sources.list.d/ploutos.list
            else
              echo -e '${{ steps.verify.outputs.deb_apt_source }}' >$HOME/ploutos.list
              sudo incus file push $HOME/ploutos.list testcon/etc/apt/sources.list.d/
            fi
            sudo incus exec testcon -- sed -i -e "s/\${OS_NAME}/${OS_NAME}/g" -e "s/\${OS_REL}/${OS_REL}/g" /etc/apt/sources.list.d/ploutos.list
            sudo incus exec testcon -- wget -q ${{ steps.verify.outputs.deb_apt_key_url }} -Oaptkey.asc
            sudo incus exec testcon -- gpg --dearmor -o /etc/apt/trusted.gpg.d/nlnetlabs-archive-keyring.gpg ./aptkey.asc
            sudo incus exec testcon -- apt-get -y update
            ;;
          centos|rockylinux|almalinux)
            if [[ -f '${{ steps.verify.outputs.rpm_yum_repo }}' ]]; then
              sudo incus file push ${{ steps.verify.outputs.rpm_yum_repo }} testcon/etc/yum.repos.d/ploutos.repo
            else
              echo -e '${{ steps.verify.outputs.rpm_yum_repo }}' >$HOME/ploutos.repo
              sudo incus file push $HOME/ploutos.repo testcon/etc/yum.repos.d/
            fi
            sudo incus exec testcon -- sed -i -e "s/\${OS_NAME}/${OS_NAME}/g" -e "s/\${OS_REL}/${OS_REL}/g" /etc/yum.repos.d/ploutos.repo
            sudo incus exec testcon -- rpm --import ${{ steps.verify.outputs.rpm_yum_key_url }}
            ;;
        esac

    - name: Install previously published package
      id: instprev
      if: ${{ steps.verify.outputs.mode == 'upgrade-from-published' }}
      run: |
        case ${OS_NAME} in
          debian|ubuntu)
            sudo incus exec testcon -- apt-get install -y ${{ steps.verify.outputs.published_pkg }}

            if [[ "${{ steps.verify.outputs.pkg }}" == "${{ steps.verify.outputs.published_pkg }}" ]]; then
              # determine the conffiles, append a harmless line break to each one (so that they are modified) then save
              # the md5sums of the modified files for comparison after upgrade to ensure our edits are not overwritten
              SAVED_MD5SUMS="/tmp/${{ steps.verify.outputs.pkg }}-conffiles.md5"
              CONFFILE_LIST_FILE="/var/lib/dpkg/info/${{ steps.verify.outputs.pkg }}.conffiles"
  
              # append a line break to the conffile
              for F in $(sudo incus exec testcon -- cat ${CONFFILE_LIST_FILE}); do
                sudo incus exec testcon -- sh -c "echo >> $F"
              done
  
              # save the md5 checksums for later comparison
              if sudo incus exec testcon -- sh -c "xargs -a ${CONFFILE_LIST_FILE} md5sum > ${SAVED_MD5SUMS}"; then
                sudo incus exec testcon -- cat ${SAVED_MD5SUMS}
              else
                echo "Conffile change preservation checking will be skipped because no conffiles were detected."
                sudo incus exec testcon -- rm -f ${SAVED_MD5SUMS}
              fi
            fi
            ;;
          centos|rockylinux|almalinux)
            if [[ -f '${{ steps.verify.outputs.rpm_yum_repo }}' ]]; then
              sudo incus file push ${{ steps.verify.outputs.rpm_yum_repo }} testcon/etc/yum.repos.d/ploutos.repo
            else
              echo -e '${{ steps.verify.outputs.rpm_yum_repo }}' >$HOME/ploutos.repo
              sudo incus file push $HOME/ploutos.repo testcon/etc/yum.repos.d/
            fi
            sudo incus exec testcon -- sed -i -e "s/\${OS_NAME}/${OS_NAME}/g" -e "s/\${OS_REL}/${OS_REL}/g" /etc/yum.repos.d/ploutos.repo
            sudo incus exec testcon -- rpm --import ${{ steps.verify.outputs.rpm_yum_key_url }}
            sudo incus exec testcon -- yum install -y ${{ steps.verify.outputs.rpm_yum_extra_args }} ${{ steps.verify.outputs.published_pkg }}
            ;;
        esac

    - name: Install the newly built package
      if: ${{ steps.verify.outputs.mode == 'fresh-install' }}
      run: |
        case ${OS_NAME} in
          debian|ubuntu)
            sudo incus exec testcon -- apt-get -y install /tmp/${PKG_FILE}
            ;;
          centos|rockylinux|almalinux)
            sudo incus exec testcon -- yum install -y /tmp/${PKG_FILE} 2>&1 | tee install.log
            # yum install exits with code 0 even if scriptlets fail, so look for some sign of failure
            ! grep -qE '(err|warn|fail)' install.log
            ;;
        esac

    - name: Test the installed package
      if: ${{ inputs.package_test_scripts_path != '' && steps.verify.outputs.mode == 'fresh-install' }}
      run: |
        TEST_SCRIPT="$(echo '${{ inputs.package_test_scripts_path }}' | sed -e 's/<package>/${{ steps.verify.outputs.pkg }}/g')"
        sudo incus file push ${TEST_SCRIPT} testcon/tmp/test.sh
        sudo incus exec testcon -- chmod +x /tmp/test.sh
        sudo incus exec testcon -- /tmp/test.sh post-install

    - name: Upgrade from the published package to the newly built package
      id: upgrade_package
      continue-on-error: true
      if: ${{ steps.verify.outputs.mode == 'upgrade-from-published' }}
      run: |
        case ${OS_NAME} in
          debian|ubuntu)
            # See https://github.com/NLnetLabs/.github/issues/17 regarding --force-confXXX
            sudo incus exec testcon -- apt-get -y -o Dpkg::Options::="--force-confdef" -o Dpkg::Options::="--force-confold" install /tmp/${PKG_FILE}
            ;;
          centos|rockylinux|almalinux)
            sudo incus exec testcon -- yum install -y /tmp/${PKG_FILE} 2>&1 | tee upgrade.log
            # yum install exits with code 0 even if scriptlets fail, so look for some sign of failure
            ! grep -qE '(err|warn|fail)' upgrade.log
            ;;
        esac

    - name: Require successful upgrade
      if: ${{ steps.upgrade_package.outcome == 'failure' && !matrix.ignore_upgrade_failure }}
      uses: actions/github-script@v7
      with:
        script: |
          core.setFailed("Package upgrade failed unexpectedly")

    - name: Verify that conffiles have not been altered by the upgrade
      if: ${{ steps.verify.outputs.mode == 'upgrade-from-published' }}
      run: |
        case ${OS_NAME} in
          debian|ubuntu)
            SAVED_MD5SUMS="/tmp/${{ steps.verify.outputs.pkg }}-conffiles.md5"
            sudo incus exec testcon -- sh -c "[ ! -f ${SAVED_MD5SUMS} ] || md5sum -c ${SAVED_MD5SUMS}"
            ;;
        esac

    - name: Test the upgraded package
      if: ${{ inputs.package_test_scripts_path != '' && steps.verify.outputs.mode == 'upgrade-from-published' }}
      run: |
        TEST_SCRIPT="$(echo '${{ inputs.package_test_scripts_path }}' | sed -e 's/<package>/${{ steps.verify.outputs.pkg }}/g')"
        sudo incus file push ${TEST_SCRIPT} testcon/tmp/test2.sh
        sudo incus exec testcon -- chmod +x /tmp/test2.sh
        sudo incus exec testcon -- /tmp/test2.sh post-upgrade

    - name: Test uninstall (without purge)
      run: |
        case ${OS_NAME} in
          debian|ubuntu)
            sudo incus exec testcon -- apt-get -y remove ${{ steps.verify.outputs.pkg }}
            ;;
          centos|rockylinux|almalinux)
            sudo incus exec testcon -- yum remove -y ${{ steps.verify.outputs.pkg }} 2>&1 | tee remove.log
            # yum remove exits with code 0 even if scriptlets fail, so look for some sign of failure
            ! grep -qE '(err|warn|fail)' remove.log
            ;;
        esac

    - name: Test re-install
      run: |
        case ${OS_NAME} in
          debian|ubuntu)
            sudo incus exec testcon -- apt-get -y install /tmp/${PKG_FILE}
            ;;
          centos|rockylinux|almalinux)
            sudo incus exec testcon -- yum install -y /tmp/${PKG_FILE} 2>&1 | tee reinstall.log
            # yum remove exits with code 0 even if scriptlets fail, so look for some sign of failure
            ! grep -qE '(err|warn|fail)' reinstall.log
            ;;
        esac


  # -------------------------------------------------------------------------------------------------------------------
  # Job: 'docker'
  # -------------------------------------------------------------------------------------------------------------------
  # Build and push architecture specific images (but NOT the main image that is used by end users). Sanity check the
  # image if possible (i.e. if it is x86-64, non-x86-64 architecture images cannot be run by this workflow yet). Logs
  # in to Docker Hub using secrets configured in this GitHub repository.
  #
  # NOTE: If you extend the set of matrix includes in this job you must also extend the call to docker manifest create
  # in the docker-manifest job below.
  docker:
    # Use of always() here ensures that even if the cross job is skipped we will still run
    if: ${{ always() && needs.prepare.outputs.docker_build_rules != '{}' }}
    needs: prepare
    outputs:
      published: ${{ steps.publish.conclusion == 'success' }}
    runs-on: ${{ inputs.runs_on }}
    strategy:
      fail-fast: false
      matrix: ${{ fromJSON(needs.prepare.outputs.docker_build_rules) }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Print matrix
        # Disable default use of bash -x for easier to read output in the log
        shell: bash
        run: |
          echo '${{ toJSON(matrix) }}'

      - name: Verify inputs
        id: verify
        run: |
          MODE="${{ matrix.mode }}"

          case ${MODE} in
            "")
              MODE="build"
              ;;

            build|copy)
              ;;

            *)
              echo "::error::Required matrix variable 'mode' in docker_build_rules must be one of 'copy' or 'build' (default)."
              exit 1
              ;;
          esac

          if [[ "${MODE}" == "copy" ]]; then
            if [[ "${{ matrix.platform }}" == "" ]]; then
              echo "::error::Matrix variable 'platform' in docker_build_rules must be a supported buildx platform. See: https://github.com/moby/buildkit#building-multi-platform-images"
              exit 1
            fi
          fi

          if [[ "${{ matrix.shortname }}" == "" ]]; then
            echo "::error::Matrix variable 'shortname' in docker_build_rules must set and non-empty."
            exit 1
          fi

          echo "mode=${MODE}" >> $GITHUB_OUTPUT

      - uses: docker/setup-qemu-action@v3
        # Don't use QEmu for compiling, it's way too slow on GitHub Actions.
        # Only use it for making images that will contain prebuilt binaries.
        if: ${{ steps.verify.outputs.mode == 'copy' }}
        with:
          platforms: ${{ matrix.platform }}

      - uses: docker/setup-buildx-action@v3
        with:
          version: v0.9.1 # See: https://github.com/docker/build-push-action/issues/755

      - name: Download cross-compiled binaries
        if: ${{ steps.verify.outputs.mode == 'copy' }}
        uses: NLnetLabs/download-artifact@main
        with:
          name: ${{ inputs.artifact_prefix }}tmp-cross-binaries-${{ matrix.target }}
          # The file downloaded to dockerbin/xxx will be used by the Dockerfile
          # Note: matrix.platform here has to match the Docker BuildX $TARGETPLATFORM variable available while building
          # the Dockerfile, e.g. linux/amd64.
          path: dockerbin/${{ matrix.platform }}
          maxTries: ${{ needs.prepare.outputs.cross_max_tries }}
          retryDelayMs: ${{ needs.prepare.outputs.cross_retry_delay_ms }}

      - name: Untar the set of downloaded binaries
        if: ${{ steps.verify.outputs.mode == 'copy' }}
        run: |
          tar vpxf dockerbin/${{ matrix.platform }}/bins.tar --transform='s/.*\///' -C dockerbin/${{ matrix.platform }}/
          find dockerbin/${{ matrix.platform }}/ -type d -empty -delete
          rm dockerbin/${{ matrix.platform }}/bins.tar

      - name: Generate architecture specific Docker image name
        id: gen
        run: |
          # Use the [0]the tag, i.e. `<repo>:unstable`, `<repo>:test` or `<repo>:v0.1.2`.
          # Don't use the [1]th tag (if present) which would be '<repo>:latest', as we won't build or publish an
          # image for 'latest' but instead push a multi-arch manifest for 'latest' which refers to the same
          # set of architecture specific images as the version specific multi-arch manifest we will publish.
          DOCKER_REPO_AND_TAG=$(echo "${{ needs.prepare.outputs.first_repo_and_tag_pair }}" | base64 -d)
          LOWER_DOCKER_ORG=$(echo "${{ needs.prepare.outputs.lower_docker_org }}" | base64 -d)
          echo "image_name=${LOWER_DOCKER_ORG}/${DOCKER_REPO_AND_TAG}-${{ matrix.shortname }}" >> $GITHUB_OUTPUT

      # Build a single architecture specific Docker image with an explicit architecture extension in the Docker
      # tag value. We have to push it to Docker Hub otherwise we can't make the multi-arch manifest below. If the
      # image fails testing (or doesn't work but wasn't caught because it is non-x86-64 which we can't at the moment
      # test here) it will have been pushed to Docker Hub but is NOT the image we expect people to use, that is the
      # combined multi-arch image that lacks the architecture specific tag value extension and that will ONLY be
      # pushed if all architecture specific images build and (where supported) passt he sanity check below.
      - name: Build Docker image ${{ steps.gen.outputs.image_name }}
        uses: docker/build-push-action@v5
        with:
          context: ${{ inputs.docker_context_path }}
          file: ${{ inputs.docker_file_path }}
          platforms: ${{ matrix.platform }}
          tags: ${{ steps.gen.outputs.image_name }}
          build-args: |
            MODE=${{ steps.verify.outputs.mode }}
            CARGO_ARGS=${{ matrix.cargo_args }}
          load: true

      - name: Save Docker image locally
        run: |
          docker save -o /tmp/docker-${{ matrix.shortname }}-img.tar ${{ steps.gen.outputs.image_name }}

      # Do a basic sanity check of the created image using the test tag to select the image to run, but only if the
      # image is for the x86-64 architecture as we don't yet have a way to run non-x86-64 architecture images.
      - name: Sanity check (linux/amd64 images only)
        if: ${{ matrix.platform == 'linux/amd64' && inputs.docker_sanity_check_command != '' }}
        run: |
          docker run --rm ${{ steps.gen.outputs.image_name }} ${{ inputs.docker_sanity_check_command }}

      - name: Log into Docker Hub
        if: ${{ fromJSON(needs.prepare.outputs.has_docker_secrets) == true }}
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_HUB_ID }}
          password: ${{ secrets.DOCKER_HUB_TOKEN }}

      # Upload the Docker image as a GitHub Actions artifact, handy when not publishing or investigating a problem
      - name: Upload built image to GitHub Actions
        uses: NLnetLabs/upload-artifact@main
        with:
          name: ${{ inputs.artifact_prefix }}tmp-docker-image-${{ matrix.shortname }}
          path: /tmp/docker-${{ matrix.shortname }}-img.tar
          if-no-files-found: warn

      - name: Publish image to Docker Hub
        id: publish
        if: ${{ fromJSON(needs.prepare.outputs.has_docker_secrets) == true && (contains(github.ref, 'refs/tags/v') || github.ref == 'refs/heads/main') }}
        uses: docker/build-push-action@v5
        with:
          context: ${{ inputs.docker_context_path }}
          file: ${{ inputs.docker_file_path }}
          platforms: ${{ matrix.platform }}
          tags: ${{ steps.gen.outputs.image_name }}
          build-args: |
            MODE=${{ steps.verify.outputs.mode }}
            CARGO_ARGS=${{ matrix.cargo_args }}
          push: true


  # -------------------------------------------------------------------------------------------------------------------
  # Job: 'docker-manifest'
  # -------------------------------------------------------------------------------------------------------------------
  # Create a Docker multi-arch "manifest" referencing the individual already pushed architecture specific images on
  # Docker Hub and push the manifest to Docker Hub as our "main" application image Docker Hub that end users will use.
  # Logs in to Docker Hub using secrets configured in this GitHub repository.
  docker-manifest:
    needs: [prepare, docker]
    outputs:
      published: ${{ steps.publish.conclusion == 'success' }}
    # Use of always() here ensures that even if the _cross_ job (note: not the 'docker' job) is skipped we will still run.
    # I wouldn't expect this to be needed but since the cross job was made conditional we seem to need this.
    if: ${{ always() && needs.prepare.outputs.docker_build_rules != '{}' && fromJSON(needs.prepare.outputs.has_docker_secrets) == true && (contains(github.ref, 'refs/tags/v') || github.ref == 'refs/heads/main') }}
    runs-on: ${{ inputs.runs_on }}
    steps:
      - name: Log into Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_HUB_ID }}
          password: ${{ secrets.DOCKER_HUB_TOKEN }}

      - name: Decode encoded Docker repo name and tag
        id: decode
        run: |
          LOWER_DOCKER_ORG=$(echo ${{ needs.prepare.outputs.lower_docker_org }} | base64 -d)
          REPO_AND_TAG_PAIRS=$(echo ${{ needs.prepare.outputs.all_repo_and_tag_pairs }} | base64 -d)

          # Convert the line-break separated tag pairs into space separated tag pairs without a trailing line break.
          # This can then easily be used with a shell for loop in the steps below.
          REPO_AND_TAG_PAIRS=$(echo ${REPO_AND_TAG_PAIRS} | tr "\n" " " | tr -d "\n")

          echo "repo_and_tag_pairs=${REPO_AND_TAG_PAIRS}" >> $GITHUB_OUTPUT
          echo "lower_docker_org=${LOWER_DOCKER_ORG}" >> $GITHUB_OUTPUT

      - name: Create multi-arch manifest(s)
        run: |
          LOWER_DOCKER_ORG="${{ steps.decode.outputs.lower_docker_org }}"

          ARCH_SHORT_NAMES="${{ join(fromJSON(needs.prepare.outputs.docker_build_rules).include.*.shortname, ' ') }}"
          REFERENCED_IMAGES=""

          # Imagine that we are invoked with two tags: v1.0.1 and latest
          # The first time round the loop we make a manifest for v1.0.1 referencing the v1.0.1 images.
          # The second time round the loop we make a manifest for latest also referencing the v1.0.1 images.
          for REPO_AND_TAG in ${{ steps.decode.outputs.repo_and_tag_pairs }}; do
            if [[ "${REFERENCED_IMAGES}" == "" ]]; then
              for ARCH_SHORT_NAME in ${ARCH_SHORT_NAMES}; do
                REFERENCED_IMAGES="${REFERENCED_IMAGES} ${LOWER_DOCKER_ORG}/${REPO_AND_TAG}-${ARCH_SHORT_NAME} "
              done
            fi

            docker manifest create --amend ${LOWER_DOCKER_ORG}/${REPO_AND_TAG} ${REFERENCED_IMAGES}
          done

      - name: Publish multi-arch image manifest(s) to Docker Hub
        id: publish
        run: |
          LOWER_DOCKER_ORG="${{ steps.decode.outputs.lower_docker_org }}"
          for REPO_AND_TAG in ${{ steps.decode.outputs.repo_and_tag_pairs }}; do
            docker manifest push ${LOWER_DOCKER_ORG}/${REPO_AND_TAG}
          done
